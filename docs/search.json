[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Nick Shuckerow",
    "section": "",
    "text": "Welcome to my website!\nI am a Systems Engineer for Raytheon"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Nick Shuckerow’s Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "projects/project1/index.html",
    "href": "projects/project1/index.html",
    "title": "Analysis of Cars",
    "section": "",
    "text": "Let’s investigate the relationship between fuel efficiency (mpg) and engine displacement (disp) from the mtcars dataset. Those variables have a correlation of -0.85.\n\n\nHere is a plot:\n\nlibrary(tidyverse)\ndata(mtcars)\nmtcars |&gt;\n  ggplot(aes(mpg, disp)) + \n  geom_point(color=\"dodgerblue4\", size=2)"
  },
  {
    "objectID": "projects/project1/index.html#sub-header",
    "href": "projects/project1/index.html#sub-header",
    "title": "Analysis of Cars",
    "section": "",
    "text": "Here is a plot:\n\nlibrary(tidyverse)\ndata(mtcars)\nmtcars |&gt;\n  ggplot(aes(mpg, disp)) + \n  geom_point(color=\"dodgerblue4\", size=2)"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "My Projects",
    "section": "",
    "text": "A Replication of Karlan and List (2007)\n\n\n\n\n\n\nNick Shuckerow\n\n\nApr 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nAnalysis of Cars\n\n\n\n\n\n\nYour Name\n\n\nApr 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/HW1/hw1_questions.html",
    "href": "projects/HW1/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThe experiment was conducted through a direct mail campaign for a liberal nonprofit organization. The authors assigned 67% of the 50,000 to the treatment group and 33% to the control group.\nThe letters sent to the treatment and control group were the same except in the following regards:\n\nThe treatment group letter had an additional paragraph saying that their donation will be matched.\nThe reply card for the treatment group had details on the matching grant.\n\nThe letters were randomized through 3 different dimensions.\n\nmatching price ratio\nmaximum match amount\nsuggested donation amount\n\nThe experiment found that using matching donations increases the revenue per solicitation and the probability that someone donates.\nIt also found that larger match ratios relative to smaller match ratios have no additional impact. This project seeks to replicate their results.\nOverall, the authors found a unique way to measure the scope of a public good (donations) in a real world setting, rather than hypothetical scenarios. This is a valuable contribution to the literature on charitable giving and public goods."
  },
  {
    "objectID": "projects/HW1/hw1_questions.html#introduction",
    "href": "projects/HW1/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThe experiment was conducted through a direct mail campaign for a liberal nonprofit organization. The authors assigned 67% of the 50,000 to the treatment group and 33% to the control group.\nThe letters sent to the treatment and control group were the same except in the following regards:\n\nThe treatment group letter had an additional paragraph saying that their donation will be matched.\nThe reply card for the treatment group had details on the matching grant.\n\nThe letters were randomized through 3 different dimensions.\n\nmatching price ratio\nmaximum match amount\nsuggested donation amount\n\nThe experiment found that using matching donations increases the revenue per solicitation and the probability that someone donates.\nIt also found that larger match ratios relative to smaller match ratios have no additional impact. This project seeks to replicate their results.\nOverall, the authors found a unique way to measure the scope of a public good (donations) in a real world setting, rather than hypothetical scenarios. This is a valuable contribution to the literature on charitable giving and public goods."
  },
  {
    "objectID": "projects/HW1/hw1_questions.html#data",
    "href": "projects/HW1/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\nThe dataset seen below which Karlan and List gathered on the 50,083 subjects has over 52 columns or variables. The main ones are concerned about for our research are ‘gave’ (if the individual donated any amount), ‘amount’ (what amount they donated), ‘treatment’ (if they were a part of the treatment or control group), and ‘ratio’ (matching ratio given to that subject).\nMany of the columns are redundant (treatmeant vs control columns, ratio columns vs ratio1, ratio2, ratio3 columns), however they allow us to more easily filter the data and make calculations.\nIn the second cell, you can see the description of variables ‘treatment’ and ‘control’. Through this, it is shown that 66% of the participants were a part of the treatment group, and 33% were a part of the control group.\nSince many of these variables are binary, a 1 or 0 is used to describe whether the participant had that treatment, variables, or attribute, which allows analysts to easily calculate proportions or percentages like with treatment and control.\n\nimport pandas as pd\nkarlan = pd.read_stata(\"karlan_list_2007.dta\")\nkarlan\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.000000\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.000000\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.000000\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.000000\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n50078\n1\n0\n1\n0\n0\n$25,000\n1\n0\n0\n0\n...\n0.0\n1.0\n0.872797\n0.089959\n0.257265\n2.13\n45047.0\n0.771316\n0.263744\n1.000000\n\n\n50079\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.688262\n0.108889\n0.288792\n2.67\n74655.0\n0.741931\n0.586466\n1.000000\n\n\n50080\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\n0.900000\n0.021311\n0.178689\n2.36\n26667.0\n0.778689\n0.107930\n0.000000\n\n\n50081\n1\n0\n3\n0\n1\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.917206\n0.008257\n0.225619\n2.57\n39530.0\n0.733988\n0.184768\n0.634903\n\n\n50082\n1\n0\n3\n0\n1\n$25,000\n1\n0\n0\n0\n...\n0.0\n1.0\n0.530023\n0.074112\n0.340698\n3.70\n48744.0\n0.717843\n0.127941\n0.994181\n\n\n\n\n50083 rows × 51 columns\n\n\n\n\n\n\n\n\n\n\nkarlan.describe()\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio2\nratio3\nsize25\nsize50\nsize100\nsizeno\naskd1\naskd2\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\ncount\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n...\n49978.000000\n49978.000000\n48217.000000\n48047.000000\n48217.000000\n48221.000000\n48209.000000\n48214.000000\n48215.000000\n48217.000000\n\n\nmean\n0.666813\n0.333187\n0.222311\n0.222211\n0.166723\n0.166623\n0.166723\n0.166743\n0.222311\n0.222291\n...\n0.510245\n0.488715\n0.819599\n0.086710\n0.321694\n2.429012\n54815.700533\n0.669418\n0.391661\n0.871968\n\n\nstd\n0.471357\n0.471357\n0.415803\n0.415736\n0.372732\n0.372643\n0.372732\n0.372750\n0.415803\n0.415790\n...\n0.499900\n0.499878\n0.168560\n0.135868\n0.103039\n0.378105\n22027.316665\n0.193405\n0.186599\n0.258633\n\n\nmin\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.009418\n0.000000\n0.000000\n0.000000\n5000.000000\n0.000000\n0.000000\n0.000000\n\n\n25%\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.755845\n0.014729\n0.258311\n2.210000\n39181.000000\n0.560222\n0.235647\n0.884929\n\n\n50%\n1.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.000000\n0.000000\n0.872797\n0.036554\n0.305534\n2.440000\n50673.000000\n0.712296\n0.373744\n1.000000\n\n\n75%\n1.000000\n1.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.000000\n1.000000\n0.938827\n0.090882\n0.369132\n2.660000\n66005.000000\n0.816798\n0.530036\n1.000000\n\n\nmax\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n...\n1.000000\n1.000000\n1.000000\n0.989622\n0.997544\n5.270000\n200001.000000\n1.000000\n1.000000\n1.000000\n\n\n\n\n8 rows × 48 columns\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\n\nMonths since last Donation Variable\n\n# Months since last donation t-test\n\nmrm2_treat = karlan[karlan['treatment'] == 1]['mrm2']\nmrm2_control = karlan[karlan['treatment'] == 0]['mrm2']\n\nmrm2_t_mean = mrm2_treat.mean()\nmrm2_c_mean = mrm2_control.mean()\n\nmrm2_t_std = mrm2_treat.std()\nmrm2_c_std = mrm2_control.std()\n\nmrm2_t_n = mrm2_treat.count()\nmrm2_c_n = mrm2_control.count()\n\nt_mrm2 = (mrm2_t_mean - mrm2_c_mean) / ((mrm2_t_std**2/mrm2_t_n) + (mrm2_c_std**2/mrm2_c_n))**0.5\n\nprint(t_mrm2)\n\n0.11953155228176905\n\n\n\n# calculate p-value\nfrom scipy import stats\n\np_mrm2 = stats.t.sf(abs(t_mrm2), mrm2_t_n + mrm2_c_n - 2) * 2\nprint(p_mrm2)\n\n# Not statistically significant\n\n0.9048547235822526\n\n\n\n# Linear Regression - mrm2\n\nimport pyrsm as rsm\n\nlr_mrm2 = rsm.regress(\n    data = karlan[['treatment', 'mrm2']],\n    evar = \"treatment\",\n    rvar = \"mrm2\"\n    )\n\nlr_mrm2.summary()\n\nLinear regression (OLS)\nData                 : Not provided\nResponse variable    : mrm2\nExplanatory variables: treatment\nNull hyp.: the effect of x on mrm2 is zero\nAlt. hyp.: the effect of x on mrm2 is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept       12.998      0.094  138.979  &lt; .001  ***\ntreatment        0.014      0.115    0.119   0.905     \n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: -0.0\nF-statistic: 0.014 df(1, 50080), p.value 0.905\nNr obs: 50,082\n\n\n\n\nCouple Variable\n\ncouple_treat = karlan[karlan['treatment'] == 1]['couple']\ncouple_control = karlan[karlan['treatment'] == 0]['couple']\n\ncouple_t_mean = couple_treat.mean()\ncouple_c_mean = couple_control.mean()\n\ncouple_t_std = couple_treat.std()\ncouple_c_std = couple_control.std()\n\ncouple_t_n = couple_treat.count()\ncouple_c_n = couple_control.count()\n\nt_couple = (couple_t_mean - couple_c_mean) / ((couple_t_std**2/couple_t_n) + (couple_c_std**2/couple_c_n))**0.5\n\nprint(t_couple)\n\n-0.5822577486768489\n\n\n\n# calculate p-value\n\np_couple = stats.t.sf(abs(t_couple), couple_t_n + couple_c_n - 2) * 2\nprint(p_couple)\n\n# Not statistically significant\n\n0.5603957630249871\n\n\n\nlr_couple = rsm.regress(\n    data = karlan[['treatment', 'couple']],\n    evar = \"treatment\",\n    rvar = \"couple\"\n    )\n\nlr_couple.summary()\n\nLinear regression (OLS)\nData                 : Not provided\nResponse variable    : couple\nExplanatory variables: treatment\nNull hyp.: the effect of x on couple is zero\nAlt. hyp.: the effect of x on couple is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.093      0.002   41.124  &lt; .001  ***\ntreatment       -0.002      0.003   -0.584   0.559     \n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: -0.0\nF-statistic: 0.341 df(1, 48933), p.value 0.559\nNr obs: 48,935\n\n\n\n\nBalance Test Results\nThe intercept coefficients calculated for mrm2 and couple variables are exactly the same as in table 1 of the paper for the control group. Also, when incorporating the coefficients for treatment (treatment = 1), they also equal the mean values in table 1 for the treatment group.\nFor mrm2 (months since last donation), the control group mean was 12.998 and that increases to 13.012 if they were a part of the treatment group. This is not a large disparity and as such did not prove to be statistically significant on a 95% confidence interval.\nFor couple (whether the donor was a couple), the control group mean was 0.093 (interpreted as 9.3% of donors in the control group were couples) and that decreases to 0.091 if they were a part of the treatment group. This is also not a large disparity and as such did not prove to be statistically significant on a 95% confidence interval."
  },
  {
    "objectID": "projects/HW1/hw1_questions.html#experimental-results",
    "href": "projects/HW1/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\n\n# find proportion of treatment group that gave money\n\ntreat_gave = karlan[karlan['treatment'] == 1]['gave'].mean()\ncontrol_gave = karlan[karlan['treatment'] == 0]['gave'].mean()\n\nprint(treat_gave, control_gave)\n\n0.02203856749311295 0.017858212980164198\n\n\n\n# create bar graph for proportion of treatment/control group that gave money\n\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots()\nax.bar(['Treatment', 'Control'], [treat_gave, control_gave])\nax.set_ylabel('Proportion of Group that Gave Money')\nax.set_title('Proportion of Treatment and Control Group that Gave Money')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n# Calculate t-stat for those who donated if they were a part of treatment or control group\n\ngave_treat = karlan[karlan['treatment'] == 1]['gave']\ngave_control = karlan[karlan['treatment'] == 0]['gave']\n\ngave_t_mean = gave_treat.mean()\ngave_c_mean = gave_control.mean()\n\ngave_t_std = gave_treat.std()\ngave_c_std = gave_control.std()\n\ngave_t_n = gave_treat.count()\ngave_c_n = gave_control.count()\n\nt_gave = (gave_t_mean - gave_c_mean) / ((gave_t_std**2/gave_t_n) + (gave_c_std**2/gave_c_n))**0.5\n\nprint(t_gave)\n\n3.2094621908279835\n\n\n\n# Calculate p-value on 95% confidence interval\n\np_gave = stats.t.sf(abs(t_gave), gave_t_n + gave_c_n - 2) * 2\np_gave\n\n# Statistically significant\n\n0.0013306730060655475\n\n\n\n# Run a linear regression which 'gave' is the response variable and 'treatment' is the explanatory variable\n\nlr_gave = rsm.regress(\n    data = karlan[['treatment', 'gave']],\n    evar = \"treatment\",\n    rvar = \"gave\"\n    )\n\nlr_gave.summary()\n\nLinear regression (OLS)\nData                 : Not provided\nResponse variable    : gave\nExplanatory variables: treatment\nNull hyp.: the effect of x on gave is zero\nAlt. hyp.: the effect of x on gave is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.018      0.001   16.225  &lt; .001  ***\ntreatment        0.004      0.001    3.101   0.002   **\n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: 0.0\nF-statistic: 9.618 df(1, 50081), p.value 0.002\nNr obs: 50,083\n\n\nThe outcome of our t-test and linear regression were both similar in that it was found at a 95% confidence interval that the treatment did cause an increase in the number of donations. The linear regression did not explain any variance in the data, however that is not as important because we are using what should be a logistic regression (binary outcome of 1 or 0 if they donated or not) with a linear regression model.\n\n\n# Run probit regression on gave and treatment variables\n\nimport statsmodels.formula.api as smf\n\nmod = smf.probit('gave ~ treatment', data=karlan)\nres = mod.fit()\nres.summary()\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n\n\n\nProbit Regression Results\n\n\nDep. Variable:\ngave\nNo. Observations:\n50083\n\n\nModel:\nProbit\nDf Residuals:\n50081\n\n\nMethod:\nMLE\nDf Model:\n1\n\n\nDate:\nMon, 15 Apr 2024\nPseudo R-squ.:\n0.0009783\n\n\nTime:\n20:18:04\nLog-Likelihood:\n-5030.5\n\n\nconverged:\nTrue\nLL-Null:\n-5035.4\n\n\nCovariance Type:\nnonrobust\nLLR p-value:\n0.001696\n\n\n\n\n\n\n\ncoef\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\nIntercept\n-2.1001\n0.023\n-90.073\n0.000\n-2.146\n-2.054\n\n\ntreatment\n0.0868\n0.028\n3.113\n0.002\n0.032\n0.141\n\n\n\n\n\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\nRatio of 1:1 vs Ratio of 2:1\n\n# Calculate t-stat for Ratio 1:1 vs Ratio 2:1\n\ngave_ratio1 = karlan[karlan['ratio'] == 1]['gave']\ngave_ratio2 = karlan[karlan['ratio'] == 2]['gave']\n\ngave_1_mean = gave_ratio1.mean()\ngave_2_mean = gave_ratio2.mean()\n\ngave_1_std = gave_ratio1.std()\ngave_2_std = gave_ratio2.std()\n\ngave_1_n = gave_ratio1.count()\ngave_2_n = gave_ratio2.count()\n\nt_gave_ratio = (gave_2_mean - gave_1_mean) / ((gave_2_std**2/gave_2_n) + (gave_1_std**2/gave_1_n))**0.5\n\nprint(t_gave_ratio)\n\n0.965048975142932\n\n\n\np_gave_ratio = stats.t.sf(abs(t_gave_ratio), gave_2_n + gave_1_n - 2) * 2\np_gave_ratio\n\n# Not statistically significant\n\n0.3345307635444439\n\n\n\n\nRatio of 2:1 vs Ratio of 3:1\n\ngave_ratio3 = karlan[karlan['ratio'] == 3]['gave']\ngave_ratio2 = karlan[karlan['ratio'] == 2]['gave']\n\ngave_3_mean = gave_ratio3.mean()\ngave_2_mean = gave_ratio2.mean()\n\ngave_3_std = gave_ratio3.std()\ngave_2_std = gave_ratio2.std()\n\ngave_3_n = gave_ratio3.count()\ngave_2_n = gave_ratio2.count()\n\nt_gave_ratio_23 = (gave_2_mean - gave_3_mean) / ((gave_2_std**2/gave_2_n) + (gave_3_std**2/gave_3_n))**0.5\n\nprint(t_gave_ratio_23)\n\n-0.05011581369764474\n\n\n\np_gave_ratio_23 = stats.t.sf(abs(t_gave_ratio_23), gave_2_n + gave_3_n - 2) * 2\np_gave_ratio_23\n\n# Not statistically significant\n\n0.9600305476910405\n\n\nThe above calculations matches what Karlan suggests in his paper, that increasing the match ratio does not increase the probability of making a donation. The above calculations show a 1:1 match ratio when compared to a 2:1 match ratio, and a 2:1 match ratio when compared to a 3:1 match ratio. We did a two-sided t-test, which has a null hypothesis stating that 2:1 is not the same as 1:1, and 3:1 is not the same as 2:1.\n\n\n#create a variable ratio1 where if ratio column equals 1, then ratio1 equlas 1, else 0\n\nkarlan['ratio1'] = karlan['ratio'].apply(lambda x: 1 if x == 1 else 0)\n\n\n# Linear regression for match ratios and treatment\n\nlr_ratio = rsm.regress(\n    data = karlan[['gave', 'ratio1', 'ratio2', 'ratio3']],\n    evar = ['ratio1', 'ratio2', 'ratio3'],\n    rvar = 'gave'\n    )  \n\nlr_ratio.summary()\n\nLinear regression (OLS)\nData                 : Not provided\nResponse variable    : gave\nExplanatory variables: ratio1, ratio2, ratio3\nNull hyp.: the effect of x on gave is zero\nAlt. hyp.: the effect of x on gave is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.018      0.001   16.225  &lt; .001  ***\nratio1           0.003      0.002    1.661   0.097    .\nratio2           0.005      0.002    2.744   0.006   **\nratio3           0.005      0.002    2.802   0.005   **\n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: 0.0\nF-statistic: 3.665 df(3, 50079), p.value 0.012\nNr obs: 50,083\n\n\nThe results of linear regression model on match ratios of 1:1, 2:1, and 3:1 show that all but a ratio of 1:1 are statistically significant. The intercept coefficient (meaning when there is no match) is 0.018, and then for ratio 1:1 it has a coefficient of 0.003, which added to 0.018 is 0.021. For ratio 2:1 and 3:1, they both have coefficients of 0.005, creating a response rate of 0.023 for both. All these response rates match table 2A in the paper.\nThe precision of these estimates also match what is in the paper for standard error. Each ratio has a standard error of 0.002, meaning that ratio 1:1 could have a varying effect on response rate between 0.001 and 0.005, and ratios 2:1 and 3:1 could vary between 0.003 and 0.007. All however remain positive when incorporating standard error, meaning that the match ratio does have a positive effect on response rate when comparing to control.\n\n\n\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\n\n# Linear Regression on Treatment to Predict donation amount\nlr_d_amount = rsm.regress(\n    data = karlan[['amount', 'treatment']],\n    evar = 'treatment',\n    rvar = 'amount'\n    )  \n\nlr_d_amount.summary()\n\nLinear regression (OLS)\nData                 : Not provided\nResponse variable    : amount\nExplanatory variables: treatment\nNull hyp.: the effect of x on amount is zero\nAlt. hyp.: the effect of x on amount is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.813      0.067   12.063  &lt; .001  ***\ntreatment        0.154      0.083    1.861   0.063    .\n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: 0.0\nF-statistic: 3.461 df(1, 50081), p.value 0.063\nNr obs: 50,083\n\n\nFrom our linear regression model to calculate dollars donated amount from whether the donor was in the treatment or control group, we can conclude that the control group donates $0.813 and being a part of the treatment group increases that amount by $0.154, bringing the estimated dollars donated amount to $0.967. Per a 95% confidence interval, the model is not statistically significant, however it is very close to being so.\n\n# Linear Regression on treatment to predict donation amounts above 0\n\nlr_d_amount_above0 = rsm.regress(\n    data = karlan[karlan['amount'] &gt; 0][['amount', 'treatment']],\n    evar = 'treatment',\n    rvar = 'amount'\n    )  \n\nlr_d_amount_above0.summary()\n\nLinear regression (OLS)\nData                 : Not provided\nResponse variable    : amount\nExplanatory variables: treatment\nNull hyp.: the effect of x on amount is zero\nAlt. hyp.: the effect of x on amount is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept       45.540      2.423   18.792  &lt; .001  ***\ntreatment       -1.668      2.872   -0.581   0.561     \n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: -0.001\nF-statistic: 0.337 df(1, 1032), p.value 0.561\nNr obs: 1,034\n\n\nAfter filtering the data to only include those who donated, the linear regression model changed significantly. The intercept coefficient is now $45.54, and the treatment coefficient is now negative $1.67. Now, the treatment group has a negative affect on amount donated, meaning that the control group donates $45.54 and the treatment group donates $43.87.\nHowever, the model is not statistically significant at 95% confidence interval.\n\n\n\n# create a histogram for all the donation amounts above 0 for the control group\n\nfig, ax = plt.subplots()\nax.hist(karlan[(karlan['amount'] &gt; 0) & (karlan['treatment'] == 0)]['amount'], bins=25)\nax.axvline(43.87, color='red')\nax.text(43.87 + 1, ax.get_ylim()[1] * 0.9, f'{43.87}', color='red')\nax.set_ylabel('Frequency')\nax.set_xlabel('Donation Amount')\nax.set_title('Frequency of Donation Amounts for Control Group')\nplt.show()\n\n\n\n\n\n\n\n\n\n# create a histogram for all the donation amounts above 0 for the treatment group\n\nfig, ax = plt.subplots()\nax.hist(karlan[(karlan['amount'] &gt; 0) & (karlan['treatment'] == 1)]['amount'], bins=25)\nax.axvline(45.54, color='red')\nax.text(45.54 + 1, ax.get_ylim()[1] * 0.9, f'{45.54}', color='red')\nax.set_ylabel('Frequency')\nax.set_xlabel('Donation Amount')\nax.set_title('Frequency of Donation Amounts for Treatment Group')\nplt.show()"
  },
  {
    "objectID": "projects/HW1/hw1_questions.html#simulation-experiment",
    "href": "projects/HW1/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\n\n\n# use a bernoulli distribution to simulate 10,000 trials for control and treatment groups using their mean percentage donated as the probabilities respectively\n\nimport numpy as np\nfrom scipy.stats import bernoulli\n\ncontrol = karlan[karlan['treatment'] == 0]['gave'].mean()\ntreatment = karlan[karlan['treatment'] == 1]['gave'].mean()\n\ncontrol_sim = bernoulli.rvs(p = control, size = 10000)\ntreatment_sim = bernoulli.rvs(p = treatment, size = 10000)\n\n# calculate cumulative average of the differences for the first 10,000 draws\n\ncum_avg = np.cumsum(treatment_sim - control_sim) / np.arange(1, 10001)\n\ncum_avg\n\narray([0.        , 0.        , 0.        , ..., 0.00470094, 0.00470047,\n       0.0047    ])\n\n\n\n# plot the cumulative average of the differences with a line plot\n\nfig, ax = plt.subplots()\nax.plot(cum_avg)\nax.axhline(treatment - control, color='red')\nax.set_ylabel('Cumulative Average of Differences')\nax.set_xlabel('Number of Draws')\nax.set_title('Cumulative Average of Differences in Proportion of Giving Money')\nplt.show()\n\n\n\n\n\n\n\n\nThe above graph shows a simulation of the differences between simulated probabilities of an individual actually donating in the treatment group and an individual donating in the control group. The control group was given a probability of 0.018 and treatment group was given a probability of 0.022, which were both calculating from the given dataset.\nWe simulated this for the control and treatment group 10,000 times to generate the graph. The red horizontal line on the graph shows the calculated difference between the treatment and control probabilities from the dataset (0.004).\nAs shown, the cumulative difference between the treatment and control group varies greatly initially, then slowly starts to vary less and less around the average difference of 0.004. With more trials, it is expected there would be even less variability and the cumulative difference would be extremely close to 0.004.\n\n\nCentral Limit Theorem\n\n\nSimulating 50 trials\n\nn_50_c = np.random.binomial(50, 0.018, 1000)\n\nn_50_c = n_50_c / 50\n\nn_50_t = np.random.binomial(50, 0.022, 1000)\n\nn_50_t = n_50_t / 50\n\nn_50 = n_50_t - n_50_c\n\n# make a histogram of n_50 so there is no spacing between the bars\n\nfig, ax = plt.subplots()\nax.hist(n_50, bins=10, rwidth=1)\nax.axvline(n_50.mean(), color='red')\nax.text(n_50.mean(), ax.get_ylim()[1]*0.9, f'{np.round(n_50.mean(),4)}', color='red', verticalalignment='center', horizontalalignment='center')\nax.set_ylabel('Frequency')\nax.set_xlabel('Difference in Proportion of Donors (Treatment - Control) in 50 Draws')\nax.set_title('Frequency of Proportion of Control Group that Gave Money in 50 Draws')\nplt.show()\n\n\n\n\n\n\n\n\n\n\nSimulating 200 trials\n\nn_200_c = np.random.binomial(200, 0.018, 1000)/200\n\nn_200_t = np.random.binomial(200, 0.022, 1000)/200\n\n\nn_200 = n_200_t - n_200_c\n\nn_200_mean = n_200.mean()\n\nfig, ax = plt.subplots()\nax.hist(n_200, bins=10, rwidth=1)\nax.axvline(n_200_mean, color='red')\nax.text(n_200_mean, ax.get_ylim()[1]*0.9, f'{np.round(n_200_mean,4)}', color='red', verticalalignment='center', horizontalalignment='center')\nax.set_ylabel('Frequency')\nax.set_xlabel('Difference in Proportion of Donors (Treatment - Control) in 200 Draws')\nax.set_title('Frequency of Proportion of Control Group that Gave Money in 200 Draws')\nplt.show()\n\n\n\n\n\n\n\n\n\n\nSimulating 500 trials\n\nn_500_c = np.random.binomial(500, 0.018, 1000)/500\n\nn_500_t = np.random.binomial(500, 0.022, 1000)/500\n\n\nn_500 = n_500_t - n_500_c\n\nn_500_mean = n_500.mean()\n\nfig, ax = plt.subplots()\nax.hist(n_500, bins=10, rwidth=1)\nax.axvline(n_500_mean, color='red')\nax.text(n_500_mean, ax.get_ylim()[1]*0.9, f'{np.round(n_500_mean,4)}', color='red', verticalalignment='center', horizontalalignment='center')\nax.set_ylabel('Frequency')\nax.set_xlabel('Difference in Proportion of Donors (Treatment - Control) in 500 Draws')\nax.set_title('Frequency of Proportion of Control Group that Gave Money in 500 Draws')\nplt.show()\n\n\n\n\n\n\n\n\n\n\nSimulating 1000 trials\n\nn_1000_c = np.random.binomial(1000, 0.018, 1000)/1000\n\nn_1000_t = np.random.binomial(1000, 0.022, 1000)/1000\n\nn_1000 = n_1000_t - n_1000_c\n\nn_1000_mean = n_1000.mean()\n\nfig, ax = plt.subplots()\nax.hist(n_1000, bins=10, rwidth=1)\nax.axvline(n_1000_mean, color='red')\nax.text(n_1000_mean, ax.get_ylim()[1]*0.9, f'{np.round(n_1000_mean,4)}', color='red', verticalalignment='center', horizontalalignment='right')\nax.set_ylabel('Frequency')\nax.set_xlabel('Difference in Proportion of Donors (Treatment - Control) in 500 Draws')\nax.set_title('Frequency of Proportion of Control Group that Gave Money in 500 Draws')\nplt.show()\n\n\n\n\n\n\n\n\nFrom the above histograms, you can see from the red vertical line that the average difference decreases as we increase the trial size of the simulation and starts to get closer to 0.004, which is the calculated difference from the dataset between the percentage that donated from the treatment group versus the control group.\nAlthough the 0 mark on the x-axis varies because of graph sizing, you can see that the outer limits of the distribution gets smaller as we increase the number of trials. This follows the central limit theorem, since as we increase the number of trials in each simulation, we will get closer and closer to the true mean or percentage. The variation or wide distribution we see in the 50 trial simulation is no longer there in the 1000 trial distribution.\nOverall, the more trials we have in our simulation or experiment, the closer we will get to the mean."
  },
  {
    "objectID": "projects/HW1/HW1.html",
    "href": "projects/HW1/HW1.html",
    "title": "Nick_Shuckerow",
    "section": "",
    "text": "import pandas as pd\nfrom scipy import stats\nkarlan = pd.read_stata(\"karlan_list_2007.dta\")\nkarlan\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.000000\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.000000\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.000000\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.000000\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n50078\n1\n0\n1\n0\n0\n$25,000\n1\n0\n0\n0\n...\n0.0\n1.0\n0.872797\n0.089959\n0.257265\n2.13\n45047.0\n0.771316\n0.263744\n1.000000\n\n\n50079\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.688262\n0.108889\n0.288792\n2.67\n74655.0\n0.741931\n0.586466\n1.000000\n\n\n50080\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\n0.900000\n0.021311\n0.178689\n2.36\n26667.0\n0.778689\n0.107930\n0.000000\n\n\n50081\n1\n0\n3\n0\n1\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.917206\n0.008257\n0.225619\n2.57\n39530.0\n0.733988\n0.184768\n0.634903\n\n\n50082\n1\n0\n3\n0\n1\n$25,000\n1\n0\n0\n0\n...\n0.0\n1.0\n0.530023\n0.074112\n0.340698\n3.70\n48744.0\n0.717843\n0.127941\n0.994181\n\n\n\n\n50083 rows × 51 columns\n\n\n\n\nkarlan.describe()\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio2\nratio3\nsize25\nsize50\nsize100\nsizeno\naskd1\naskd2\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\ncount\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n...\n49978.000000\n49978.000000\n48217.000000\n48047.000000\n48217.000000\n48221.000000\n48209.000000\n48214.000000\n48215.000000\n48217.000000\n\n\nmean\n0.666813\n0.333187\n0.222311\n0.222211\n0.166723\n0.166623\n0.166723\n0.166743\n0.222311\n0.222291\n...\n0.510245\n0.488715\n0.819599\n0.086710\n0.321694\n2.429012\n54815.700533\n0.669418\n0.391661\n0.871968\n\n\nstd\n0.471357\n0.471357\n0.415803\n0.415736\n0.372732\n0.372643\n0.372732\n0.372750\n0.415803\n0.415790\n...\n0.499900\n0.499878\n0.168560\n0.135868\n0.103039\n0.378105\n22027.316665\n0.193405\n0.186599\n0.258633\n\n\nmin\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.009418\n0.000000\n0.000000\n0.000000\n5000.000000\n0.000000\n0.000000\n0.000000\n\n\n25%\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.755845\n0.014729\n0.258311\n2.210000\n39181.000000\n0.560222\n0.235647\n0.884929\n\n\n50%\n1.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.000000\n0.000000\n0.872797\n0.036554\n0.305534\n2.440000\n50673.000000\n0.712296\n0.373744\n1.000000\n\n\n75%\n1.000000\n1.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.000000\n1.000000\n0.938827\n0.090882\n0.369132\n2.660000\n66005.000000\n0.816798\n0.530036\n1.000000\n\n\nmax\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n...\n1.000000\n1.000000\n1.000000\n0.989622\n0.997544\n5.270000\n200001.000000\n1.000000\n1.000000\n1.000000\n\n\n\n\n8 rows × 48 columns\n\n\n\n\nkarlan.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 50083 entries, 0 to 50082\nData columns (total 51 columns):\n #   Column              Non-Null Count  Dtype   \n---  ------              --------------  -----   \n 0   treatment           50083 non-null  int8    \n 1   control             50083 non-null  int8    \n 2   ratio               50083 non-null  category\n 3   ratio2              50083 non-null  int8    \n 4   ratio3              50083 non-null  int8    \n 5   size                50083 non-null  category\n 6   size25              50083 non-null  int8    \n 7   size50              50083 non-null  int8    \n 8   size100             50083 non-null  int8    \n 9   sizeno              50083 non-null  int8    \n 10  ask                 50083 non-null  category\n 11  askd1               50083 non-null  int8    \n 12  askd2               50083 non-null  int8    \n 13  askd3               50083 non-null  int8    \n 14  ask1                50083 non-null  int16   \n 15  ask2                50083 non-null  int16   \n 16  ask3                50083 non-null  int16   \n 17  amount              50083 non-null  float32 \n 18  gave                50083 non-null  int8    \n 19  amountchange        50083 non-null  float32 \n 20  hpa                 50083 non-null  float32 \n 21  ltmedmra            50083 non-null  int8    \n 22  freq                50083 non-null  int16   \n 23  years               50082 non-null  float64 \n 24  year5               50083 non-null  int8    \n 25  mrm2                50082 non-null  float64 \n 26  dormant             50083 non-null  int8    \n 27  female              48972 non-null  float64 \n 28  couple              48935 non-null  float64 \n 29  state50one          50083 non-null  int8    \n 30  nonlit              49631 non-null  float64 \n 31  cases               49631 non-null  float64 \n 32  statecnt            50083 non-null  float32 \n 33  stateresponse       50083 non-null  float32 \n 34  stateresponset      50083 non-null  float32 \n 35  stateresponsec      50080 non-null  float32 \n 36  stateresponsetminc  50080 non-null  float32 \n 37  perbush             50048 non-null  float32 \n 38  close25             50048 non-null  float64 \n 39  red0                50048 non-null  float64 \n 40  blue0               50048 non-null  float64 \n 41  redcty              49978 non-null  float64 \n 42  bluecty             49978 non-null  float64 \n 43  pwhite              48217 non-null  float32 \n 44  pblack              48047 non-null  float32 \n 45  page18_39           48217 non-null  float32 \n 46  ave_hh_sz           48221 non-null  float32 \n 47  median_hhincome     48209 non-null  float64 \n 48  powner              48214 non-null  float32 \n 49  psch_atlstba        48215 non-null  float32 \n 50  pop_propurban       48217 non-null  float32 \ndtypes: category(3), float32(16), float64(12), int16(4), int8(16)\nmemory usage: 8.9 MB\n\n\n\n# write karlan to csv\n\nkarlan.to_csv(\"karlan.csv\")\n\n\n# Months since last donation t-test\n\nmrm2_treat = karlan[karlan['treatment'] == 1]['mrm2']\nmrm2_control = karlan[karlan['treatment'] == 0]['mrm2']\n\nmrm2_t_mean = mrm2_treat.mean()\nmrm2_c_mean = mrm2_control.mean()\n\nmrm2_t_std = mrm2_treat.std()\nmrm2_c_std = mrm2_control.std()\n\nmrm2_t_n = mrm2_treat.count()\nmrm2_c_n = mrm2_control.count()\n\nt_mrm2 = (mrm2_t_mean - mrm2_c_mean) / ((mrm2_t_std**2/mrm2_t_n) + (mrm2_c_std**2/mrm2_c_n))**0.5\n\nprint(t_mrm2)\n\n\n0.11953155228176905\n\n\n\n# calculate p-value\n\np_mrm2 = stats.t.sf(abs(t_mrm2), mrm2_t_n + mrm2_c_n - 2) * 2\np_mrm2\n\n# Not statistically significant\n\n0.9048547235822526\n\n\n\ncouple_treat = karlan[karlan['treatment'] == 1]['couple']\ncouple_control = karlan[karlan['treatment'] == 0]['couple']\n\ncouple_t_mean = couple_treat.mean()\ncouple_c_mean = couple_control.mean()\n\ncouple_t_std = couple_treat.std()\ncouple_c_std = couple_control.std()\n\ncouple_t_n = couple_treat.count()\ncouple_c_n = couple_control.count()\n\nt_couple = (couple_t_mean - couple_c_mean) / ((couple_t_std**2/couple_t_n) + (couple_c_std**2/couple_c_n))**0.5\n\nt_couple\n\n-0.5822577486768489\n\n\n\n# calculate p-value\n\np_couple = stats.t.sf(abs(t_couple), couple_t_n + couple_c_n - 2) * 2\np_couple\n\n# Not statistically significant\n\n0.5603957630249871\n\n\n\n# Linear Regression - mrm2\n\nimport pyrsm as rsm\n\nlr_mrm2 = rsm.regress(\n    data = karlan[['treatment', 'mrm2']],\n    evar = \"treatment\",\n    rvar = \"mrm2\"\n    )\n\nlr_mrm2.summary()\n\n\n\n\nLinear regression (OLS)\nData                 : Not provided\nResponse variable    : mrm2\nExplanatory variables: treatment\nNull hyp.: the effect of x on mrm2 is zero\nAlt. hyp.: the effect of x on mrm2 is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept       12.998      0.094  138.979  &lt; .001  ***\ntreatment        0.014      0.115    0.119   0.905     \n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: -0.0\nF-statistic: 0.014 df(1, 50080), p.value 0.905\nNr obs: 50,082\n\n\n\nlr_couple = rsm.regress(\n    data = karlan[['treatment', 'couple']],\n    evar = \"treatment\",\n    rvar = \"couple\"\n    )\n\nlr_couple.summary()\n\nLinear regression (OLS)\nData                 : Not provided\nResponse variable    : couple\nExplanatory variables: treatment\nNull hyp.: the effect of x on couple is zero\nAlt. hyp.: the effect of x on couple is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.093      0.002   41.124  &lt; .001  ***\ntreatment       -0.002      0.003   -0.584   0.559     \n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: -0.0\nF-statistic: 0.341 df(1, 48933), p.value 0.559\nNr obs: 48,935\n\n\nThe intercept coefficients calculated for mrm2 and couple variables are exactly the same as in table 1 of the paper for the control group. Also, when incorporating the coefficients for treatment (treatment = 1), they also equal the mean values in table 1 for the treatment group.\nFor mrm2 (months since last donation), the control group mean was 12.998 and that increases to 13.012 if they were a part of the treatment group. This is not a large disparity and as such did not prove to be statistically significant on a 95% confidence interval.\nFor couple (whether the donor was a couple), the control group mean was 0.093 (interpreted as 9.3% of donors in the control group were couples) and that decreases to 0.091 if they were a part of the treatment group. This is also not a large disparity and as such did not prove to be statistically significant on a 95% confidence interval.\n\n# find proportion of treatment group that gave money\n\ntreat_gave = karlan[karlan['treatment'] == 1]['gave'].mean()\ncontrol_gave = karlan[karlan['treatment'] == 0]['gave'].mean()\n\ntreat_gave, control_gave\n\n(0.02203856749311295, 0.017858212980164198)\n\n\n\n# create bar graph for proportion of treatment/control group that gave money\n\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots()\nax.bar(['Treatment', 'Control'], [treat_gave, control_gave])\nax.set_ylabel('Proportion of Group that Gave Money')\nax.set_title('Proportion of Treatment and Control Group that Gave Money')\nplt.show()\n\n\n\n\n\n\n\n\n\ngave_treat = karlan[karlan['treatment'] == 1]['gave']\ngave_control = karlan[karlan['treatment'] == 0]['gave']\n\ngave_t_mean = gave_treat.mean()\ngave_c_mean = gave_control.mean()\n\ngave_t_std = gave_treat.std()\ngave_c_std = gave_control.std()\n\ngave_t_n = gave_treat.count()\ngave_c_n = gave_control.count()\n\nt_gave = (gave_t_mean - gave_c_mean) / ((gave_t_std**2/gave_t_n) + (gave_c_std**2/gave_c_n))**0.5\n\nt_gave\n\n3.2094621908279835\n\n\n\np_gave = stats.t.sf(abs(t_gave), gave_t_n + gave_c_n - 2) * 2\np_gave\n\n# Statistically significant\n\n0.0013306730060655475\n\n\n\nlr_gave = rsm.regress(\n    data = karlan[['treatment', 'gave']],\n    evar = \"treatment\",\n    rvar = \"gave\"\n    )\n\nlr_gave.summary()\n\nLinear regression (OLS)\nData                 : Not provided\nResponse variable    : gave\nExplanatory variables: treatment\nNull hyp.: the effect of x on gave is zero\nAlt. hyp.: the effect of x on gave is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.018      0.001   16.225  &lt; .001  ***\ntreatment        0.004      0.001    3.101   0.002   **\n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: 0.0\nF-statistic: 9.618 df(1, 50081), p.value 0.002\nNr obs: 50,083\n\n\nThe outcome of our t-test and linear regression were both similar in that it was found at a 95% confidence interval that the treatment did cause an increase in the number of donations. The linear regression did not explain any variance in the data, however that is not as important because we are using what should be a logistic regression (binary outcome of 1 or 0 for if they donated or not) with a linear regression model.\n\nimport statsmodels.formula.api as smf\n\n\nmod = smf.probit('gave ~ treatment', data=karlan)\n\n\nres = mod.fit()\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n\n\n\nres.summary()\n\n\nProbit Regression Results\n\n\nDep. Variable:\ngave\nNo. Observations:\n50083\n\n\nModel:\nProbit\nDf Residuals:\n50081\n\n\nMethod:\nMLE\nDf Model:\n1\n\n\nDate:\nSun, 14 Apr 2024\nPseudo R-squ.:\n0.0009783\n\n\nTime:\n21:43:24\nLog-Likelihood:\n-5030.5\n\n\nconverged:\nTrue\nLL-Null:\n-5035.4\n\n\nCovariance Type:\nnonrobust\nLLR p-value:\n0.001696\n\n\n\n\n\n\n\ncoef\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\nIntercept\n-2.1001\n0.023\n-90.073\n0.000\n-2.146\n-2.054\n\n\ntreatment\n0.0868\n0.028\n3.113\n0.002\n0.032\n0.141\n\n\n\n\n\n\ngave_ratio1 = karlan[karlan['ratio'] == 1]['gave']\ngave_ratio2 = karlan[karlan['ratio'] == 2]['gave']\n\ngave_1_mean = gave_ratio1.mean()\ngave_2_mean = gave_ratio2.mean()\n\ngave_1_std = gave_ratio1.std()\ngave_2_std = gave_ratio2.std()\n\ngave_1_n = gave_ratio1.count()\ngave_2_n = gave_ratio2.count()\n\nt_gave_ratio = (gave_2_mean - gave_1_mean) / ((gave_2_std**2/gave_2_n) + (gave_1_std**2/gave_1_n))**0.5\n\nt_gave_ratio\n\n0.965048975142932\n\n\n\ngave_1_mean, gave_2_mean\n\n(0.020749124225276205, 0.0226333752469912)\n\n\n\np_gave_ratio = stats.t.sf(abs(t_gave_ratio), gave_2_n + gave_1_n - 2) * 2\np_gave_ratio\n\n# Not statistically significant\n\n0.3345307635444439\n\n\n\ngave_ratio3 = karlan[karlan['ratio'] == 3]['gave']\ngave_ratio2 = karlan[karlan['ratio'] == 2]['gave']\n\ngave_3_mean = gave_ratio3.mean()\ngave_2_mean = gave_ratio2.mean()\n\ngave_3_std = gave_ratio3.std()\ngave_2_std = gave_ratio2.std()\n\ngave_3_n = gave_ratio3.count()\ngave_2_n = gave_ratio2.count()\n\nt_gave_ratio_23 = (gave_2_mean - gave_3_mean) / ((gave_2_std**2/gave_2_n) + (gave_3_std**2/gave_3_n))**0.5\n\nt_gave_ratio_23\n\n-0.05011581369764474\n\n\n\np_gave_ratio_23 = stats.t.sf(abs(t_gave_ratio_23), gave_2_n + gave_3_n - 2) * 2\np_gave_ratio_23\n\n# Not statistically significant\n\n0.9600305476910405\n\n\nThe above calculations matches what Karlan suggests in his paper, that increasing the match ratio does not increase the probability of making a donation. The above calculations show a 1:1 match ratio when compared to a 2:1 match ratio, and a 2:1 match ratio when compared to a 3:1 match ratio. We did a two-sided t-test, which has a null hypothesis stating that 2:1 is not the same as 1:1, and 3:1 is not the same as 2:1.\n\n#create a variable ratio1 where if ratio column equals 1, then ratio1 equlas 1, else 0\n\nkarlan['ratio1'] = karlan['ratio'].apply(lambda x: 1 if x == 1 else 0)\n\n\n# Linear regression for match ratios and treatment\n\nlr_ratio = rsm.regress(\n    data = karlan[['gave', 'ratio1', 'ratio2', 'ratio3']],\n    evar = ['ratio1', 'ratio2', 'ratio3'],\n    rvar = 'gave'\n    )  \n\nlr_ratio.summary()\n\nLinear regression (OLS)\nData                 : Not provided\nResponse variable    : gave\nExplanatory variables: ratio1, ratio2, ratio3\nNull hyp.: the effect of x on gave is zero\nAlt. hyp.: the effect of x on gave is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.018      0.001   16.225  &lt; .001  ***\nratio1           0.003      0.002    1.661   0.097    .\nratio2           0.005      0.002    2.744   0.006   **\nratio3           0.005      0.002    2.802   0.005   **\n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: 0.0\nF-statistic: 3.665 df(3, 50079), p.value 0.012\nNr obs: 50,083\n\n\nThe results of linear regression model on match ratios of 1:1, 2:1, and 3:1 show that all but a ratio of 1:1 are statistically significant. The intercept coefficient (meaning when there is no match) is 0.018, and then for ratio 1:1 it has a coefficient of 0.003, which added to 0.018 is 0.021. For ratio 2:1 and 3:1, they both have coefficients of 0.005, creating a response rate of 0.023 for both. All these response rates match table 2A in the paper.\nThe precision of these estimates also match what is in the paper for standard error. Each ratio has a standard error of 0.002, meaning that ratio 1:1 could have a varying effect on response rate between 0.001 and 0.005, and ratios 2:1 and 3:1 could vary between 0.003 and 0.007. All however remain positive when incorporating standard error, meaning that the match ratio does have a positive effect on response rate when comparing to control.\nThe difference in responsive rate between 1:1 and 2:1 match ratios is 0.002, and between 2:1 and 3:1 match ratios is 0. From this, we can conclude that increasing makes a very small difference from 1:1 to 2:1 but no difference between 2:1 and 3:1. Overall, increasing the match donation above 1:1 does not make a large difference in response rate.\n\nlr_d_amount = rsm.regress(\n    data = karlan[['amount', 'treatment']],\n    evar = 'treatment',\n    rvar = 'amount'\n    )  \n\nlr_d_amount.summary()\n\nLinear regression (OLS)\nData                 : Not provided\nResponse variable    : amount\nExplanatory variables: treatment\nNull hyp.: the effect of x on amount is zero\nAlt. hyp.: the effect of x on amount is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.813      0.067   12.063  &lt; .001  ***\ntreatment        0.154      0.083    1.861   0.063    .\n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: 0.0\nF-statistic: 3.461 df(1, 50081), p.value 0.063\nNr obs: 50,083\n\n\nFrom our linear regression model to calculate dollars donated amount from whether the donor was in the treatment or control group, we can conclude that the control group donates $0.813 and being a part of the treatment group increases that amount by $0.154, bringing the estimated dollars donated amount to $0.967. Per a 95% confidence interval, the model is not statistically significant, however it is very close to being so.\n\nlr_d_amount_above0 = rsm.regress(\n    data = karlan[karlan['amount'] &gt; 0][['amount', 'treatment']],\n    evar = 'treatment',\n    rvar = 'amount'\n    )  \n\nlr_d_amount_above0.summary()\n\nLinear regression (OLS)\nData                 : Not provided\nResponse variable    : amount\nExplanatory variables: treatment\nNull hyp.: the effect of x on amount is zero\nAlt. hyp.: the effect of x on amount is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept       45.540      2.423   18.792  &lt; .001  ***\ntreatment       -1.668      2.872   -0.581   0.561     \n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: -0.001\nF-statistic: 0.337 df(1, 1032), p.value 0.561\nNr obs: 1,034\n\n\nAfter filtering the data to only include those who donated, the linear regression model changed significantly. The intercept coefficient is now $45.54, and the treatment coefficient is now negative $1.67. Now, the treatment group has a negative affect on amount donated, meaning that the control group donates $45.54 and the treatment group donates $43.87.\nHowever, the model is not statistically significant at 95% confidence interval.\n\n# create a histogram for all the donation amounts above 0 for the control group\n# have bin intervals be 25\n\nfig, ax = plt.subplots()\nax.hist(karlan[(karlan['amount'] &gt; 0) & (karlan['treatment'] == 0)]['amount'], bins=25)\nax.axvline(43.87, color='red')\nax.text(43.87 + 1, ax.get_ylim()[1] * 0.9, f'{43.87}', color='red')\nax.set_ylabel('Frequency')\nax.set_xlabel('Donation Amount')\nax.set_title('Frequency of Donation Amounts for Control Group')\nplt.show()\n\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots()\nax.hist(karlan[(karlan['amount'] &gt; 0) & (karlan['treatment'] == 1)]['amount'], bins=25)\nax.axvline(45.54, color='red')\nax.text(45.54 + 1, ax.get_ylim()[1] * 0.9, f'{45.54}', color='red')\nax.set_ylabel('Frequency')\nax.set_xlabel('Donation Amount')\nax.set_title('Frequency of Donation Amounts for Treatment Group')\nplt.show()\n\n# add a line to the histogram at 43.87 and display the number 43.87\n\n\n\n\n\n\n\n\n\n\n\n\n\n# simulate 10,000 draws from the control distribution and 10,000 draws from the treatment distribution. You'll then calculate a vector of 10,000 differences, and then you'll plot the cumulative average of that vector of differences. Comment on whether the cumulative average approaches the true difference in means.\n\nimport numpy as np\nfrom scipy.stats import bernoulli\n\ncontrol = karlan[karlan['treatment'] == 0]['gave'].mean()\ntreatment = karlan[karlan['treatment'] == 1]['gave'].mean()\n\nprint(control, treatment)\n\n(0.017858212980164198, 0.02203856749311295)\n\n\n\ncontrol_sim = bernoulli.rvs(p = control, size = 10000)\ntreatment_sim = bernoulli.rvs(p = treatment, size = 10000)\n\n\ncontrol_sim.mean(), treatment_sim.mean()\n\n(0.0163, 0.0213)\n\n\n\n# calculate cumulative average of the differences for the first 10,000 draws\n\ncum_avg = np.cumsum(treatment_sim - control_sim) / np.arange(1, 10001)\n\ncum_avg\n\narray([0.       , 0.       , 0.       , ..., 0.005001 , 0.0050005,\n       0.005    ])\n\n\n\n# plot the cumulative average of the differences with a line plot\n\nfig, ax = plt.subplots()\nax.plot(cum_avg)\nax.axhline(treatment - control, color='red')\nax.set_ylabel('Cumulative Average of Differences')\nax.set_xlabel('Number of Draws')\nax.set_title('Cumulative Average of Differences in Proportion of Giving Money')\nplt.show()\n\n\n\n\n\n\n\n\nThe above graph shows a simulation of the differences between simulated probabilities of an individual actually donating in the treatment group and an individual donating in the control group. The control group was given a probability of 0.018 and treatment group was given a probability of 0.022, which were both calculating from the given dataset.\nWe simulated this for the control and treatment group 10,000 times to generate the graph. The red horizontal line on the graph shows the calculated difference between the treatment and control probabilities from the dataset (0.004).\nAs shown, the cumulative difference between the treatment and control group varies greatly initially, then slowly starts to vary less and less around the average difference of 0.004. With more trials, it is expected there would be even less variability and the cumulative difference would be extremely close to 0.004.\n\nn_50_c = np.random.binomial(50, 0.018, 1000)\n\nn_50_c = n_50_c / 50\n\nn_50_t = np.random.binomial(50, 0.022, 1000)\n\nn_50_t = n_50_t / 50\n\nn_50 = n_50_t - n_50_c\n\n\n# make a histogram of n_50 so there is no spacing between the bars\n\nfig, ax = plt.subplots()\nax.hist(n_50, bins=10, rwidth=1)\nax.axvline(n_50.mean(), color='red')\nax.text(n_50.mean(), ax.get_ylim()[1], f'{np.round(n_50.mean(),4)}', color='red', verticalalignment='center', horizontalalignment='center')\nax.set_ylabel('Frequency')\nax.set_xlabel('Difference in Proportion of Donors (Treatment - Control) in 50 Draws')\nax.set_title('Frequency of Proportion of Control Group that Gave Money in 50 Draws')\nplt.show()\n\n\n\n\n\n\n\n\n\nn_200_c = np.random.binomial(200, 0.018, 1000)/200\n\nn_200_t = np.random.binomial(200, 0.022, 1000)/200\n\n\nn_200 = n_200_t - n_200_c\n\nn_200_mean = n_200.mean()\n\nn_200_mean\n\n0.00452\n\n\n\nfig, ax = plt.subplots()\nax.hist(n_200, bins=10, rwidth=1)\nax.axvline(n_200_mean, color='red')\nax.text(n_200_mean, ax.get_ylim()[1], f'{np.round(n_200_mean,4)}', color='red', verticalalignment='center', horizontalalignment='center')\nax.set_ylabel('Frequency')\nax.set_xlabel('Difference in Proportion of Donors (Treatment - Control) in 200 Draws')\nax.set_title('Frequency of Proportion of Control Group that Gave Money in 200 Draws')\nplt.show()\n\n\n\n\n\n\n\n\n\nn_500_c = np.random.binomial(500, 0.018, 1000)/500\n\nn_500_t = np.random.binomial(500, 0.022, 1000)/500\n\n\nn_500 = n_500_t - n_500_c\n\nn_500_mean = n_500.mean()\n\nn_500_mean\n\n0.0040739999999999995\n\n\n\nfig, ax = plt.subplots()\nax.hist(n_500, bins=10, rwidth=1)\nax.axvline(n_500_mean, color='red')\nax.text(n_500_mean, ax.get_ylim()[1], f'{np.round(n_500_mean,4)}', color='red', verticalalignment='center', horizontalalignment='center')\nax.set_ylabel('Frequency')\nax.set_xlabel('Difference in Proportion of Donors (Treatment - Control) in 500 Draws')\nax.set_title('Frequency of Proportion of Control Group that Gave Money in 500 Draws')\nplt.show()\n\n\n\n\n\n\n\n\n\nn_1000_c = np.random.binomial(1000, 0.018, 1000)/1000\n\nn_1000_t = np.random.binomial(1000, 0.022, 1000)/1000\n\nn_1000 = n_1000_t - n_1000_c\n\nn_1000_mean = n_1000.mean()\n\nn_1000_mean\n\n0.004085\n\n\n\nfig, ax = plt.subplots()\nax.hist(n_1000, bins=10, rwidth=1)\nax.axvline(n_1000_mean, color='red')\nax.text(n_1000_mean, ax.get_ylim()[1]*0.9, f'{np.round(n_1000_mean,4)}', color='red', verticalalignment='center', horizontalalignment='right')\nax.set_ylabel('Frequency')\nax.set_xlabel('Difference in Proportion of Donors (Treatment - Control) in 500 Draws')\nax.set_title('Frequency of Proportion of Control Group that Gave Money in 500 Draws')\nplt.show()"
  }
]