{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This post implements a few measure of variable importance, interpreted as a key drivers analysis, for certain aspects of a payment card on customer satisfaction with that payment card.\n",
    "\n",
    "\n",
    "_todo: replicate the table on slide 19 of the session 4 slides. This involves calculating pearson correlations, standardized regression coefficients, \"usefulness\", Shapley values for a linear regression, Johnson's relative weights, and the mean decrease in the gini coefficient from a random forest. You may use packages built into R or Python._\n",
    "\n",
    "_If you want a challenge, either (1) implement one or more of the measures yourself. \"Usefulness\" is rather easy to program up. Shapley values for linear regression are a bit more work. Or (2) add additional measures to the table such as the importance scores from XGBoost._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>id</th>\n",
       "      <th>satisfaction</th>\n",
       "      <th>trust</th>\n",
       "      <th>build</th>\n",
       "      <th>differs</th>\n",
       "      <th>easy</th>\n",
       "      <th>appealing</th>\n",
       "      <th>rewarding</th>\n",
       "      <th>popular</th>\n",
       "      <th>service</th>\n",
       "      <th>impact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>197</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>317</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>356</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   brand   id  satisfaction  trust  build  differs  easy  appealing  \\\n",
       "0      1   98             3      1      0        1     1          1   \n",
       "1      1  179             5      0      0        0     0          0   \n",
       "2      1  197             3      1      0        0     1          1   \n",
       "3      1  317             1      0      0        0     0          1   \n",
       "4      1  356             4      1      1        1     1          1   \n",
       "\n",
       "   rewarding  popular  service  impact  \n",
       "0          0        0        1       0  \n",
       "1          0        0        0       0  \n",
       "2          1        0        1       1  \n",
       "3          0        1        1       1  \n",
       "4          1        1        1       1  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data_for_drivers_analysis.csv')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2553 entries, 0 to 2552\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype\n",
      "---  ------        --------------  -----\n",
      " 0   brand         2553 non-null   int64\n",
      " 1   id            2553 non-null   int64\n",
      " 2   satisfaction  2553 non-null   int64\n",
      " 3   trust         2553 non-null   int64\n",
      " 4   build         2553 non-null   int64\n",
      " 5   differs       2553 non-null   int64\n",
      " 6   easy          2553 non-null   int64\n",
      " 7   appealing     2553 non-null   int64\n",
      " 8   rewarding     2553 non-null   int64\n",
      " 9   popular       2553 non-null   int64\n",
      " 10  service       2553 non-null   int64\n",
      " 11  impact        2553 non-null   int64\n",
      "dtypes: int64(12)\n",
      "memory usage: 239.5 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>id</th>\n",
       "      <th>satisfaction</th>\n",
       "      <th>trust</th>\n",
       "      <th>build</th>\n",
       "      <th>differs</th>\n",
       "      <th>easy</th>\n",
       "      <th>appealing</th>\n",
       "      <th>rewarding</th>\n",
       "      <th>popular</th>\n",
       "      <th>service</th>\n",
       "      <th>impact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2553.000000</td>\n",
       "      <td>2553.000000</td>\n",
       "      <td>2553.000000</td>\n",
       "      <td>2553.000000</td>\n",
       "      <td>2553.000000</td>\n",
       "      <td>2553.000000</td>\n",
       "      <td>2553.000000</td>\n",
       "      <td>2553.000000</td>\n",
       "      <td>2553.000000</td>\n",
       "      <td>2553.000000</td>\n",
       "      <td>2553.000000</td>\n",
       "      <td>2553.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.857423</td>\n",
       "      <td>8931.480611</td>\n",
       "      <td>3.386604</td>\n",
       "      <td>0.549550</td>\n",
       "      <td>0.461810</td>\n",
       "      <td>0.334508</td>\n",
       "      <td>0.536232</td>\n",
       "      <td>0.451234</td>\n",
       "      <td>0.451234</td>\n",
       "      <td>0.536232</td>\n",
       "      <td>0.467293</td>\n",
       "      <td>0.330983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.830096</td>\n",
       "      <td>5114.287849</td>\n",
       "      <td>1.172006</td>\n",
       "      <td>0.497636</td>\n",
       "      <td>0.498637</td>\n",
       "      <td>0.471911</td>\n",
       "      <td>0.498783</td>\n",
       "      <td>0.497714</td>\n",
       "      <td>0.497714</td>\n",
       "      <td>0.498783</td>\n",
       "      <td>0.499027</td>\n",
       "      <td>0.470659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>4310.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>8924.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>13545.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>18088.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             brand            id  satisfaction        trust        build  \\\n",
       "count  2553.000000   2553.000000   2553.000000  2553.000000  2553.000000   \n",
       "mean      4.857423   8931.480611      3.386604     0.549550     0.461810   \n",
       "std       2.830096   5114.287849      1.172006     0.497636     0.498637   \n",
       "min       1.000000     88.000000      1.000000     0.000000     0.000000   \n",
       "25%       3.000000   4310.000000      3.000000     0.000000     0.000000   \n",
       "50%       4.000000   8924.000000      4.000000     1.000000     0.000000   \n",
       "75%       6.000000  13545.000000      4.000000     1.000000     1.000000   \n",
       "max      10.000000  18088.000000      5.000000     1.000000     1.000000   \n",
       "\n",
       "           differs         easy    appealing    rewarding      popular  \\\n",
       "count  2553.000000  2553.000000  2553.000000  2553.000000  2553.000000   \n",
       "mean      0.334508     0.536232     0.451234     0.451234     0.536232   \n",
       "std       0.471911     0.498783     0.497714     0.497714     0.498783   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     1.000000     0.000000     0.000000     1.000000   \n",
       "75%       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "           service       impact  \n",
       "count  2553.000000  2553.000000  \n",
       "mean      0.467293     0.330983  \n",
       "std       0.499027     0.470659  \n",
       "min       0.000000     0.000000  \n",
       "25%       0.000000     0.000000  \n",
       "50%       0.000000     0.000000  \n",
       "75%       1.000000     1.000000  \n",
       "max       1.000000     1.000000  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.brand.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "940"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2553, 12)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pearson Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate pearson correlations with satisfaction being the y variable and the rest being the x variables\n",
    "\n",
    "satisfaction = data.drop(['id', 'brand'], axis=1)\n",
    "\n",
    "correlations = satisfaction.corr()['satisfaction'].sort_values(ascending=False)\n",
    "\n",
    "# drop satisfaction from correlations\n",
    "\n",
    "correlations = correlations.drop('satisfaction')\n",
    "\n",
    "correlations = pd.DataFrame(correlations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "correlations = correlations.rename(columns={'satisfaction': 'Pearson_Corr'})\n",
    "\n",
    "\n",
    "correlations['Pearson_Corr_%'] = round(correlations['Pearson_Corr']/correlations['Pearson_Corr'].sum(), 3)\n",
    "\n",
    "# rename satisfaction column to Pearson_Corr\n",
    "\n",
    "# drop PEARSON_CORR from correlations\n",
    "\n",
    "correlations = correlations.drop('Pearson_Corr', axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['brand', 'id', 'satisfaction', 'trust', 'build', 'differs', 'easy',\n",
       "       'appealing', 'rewarding', 'popular', 'service', 'impact'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polychoric Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects import pandas2ri\n",
    "\n",
    "# Activate the pandas2ri conversion\n",
    "pandas2ri.activate()\n",
    "\n",
    "\n",
    "# Specify the columns of interest\n",
    "columns_of_interest = ['trust', 'build', 'differs', 'easy', 'appealing', 'rewarding', 'popular', 'service', 'impact']\n",
    "\n",
    "# Initialize a list to store the results\n",
    "correlation = []\n",
    "\n",
    "# Define the R code for calculating polychoric correlation\n",
    "r_code = \"\"\"\n",
    "library(polycor)\n",
    "polychoric_corr <- function(x, y) {\n",
    "    result <- polychor(x, y)\n",
    "    return(result)\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Load the R code into the R environment\n",
    "robjects.r(r_code)\n",
    "\n",
    "# Get the polychoric_corr function\n",
    "polychoric_corr = robjects.globalenv['polychoric_corr']\n",
    "\n",
    "# Calculate polychoric correlations between 'satisfaction' and each specified column\n",
    "for col in columns_of_interest:\n",
    "    r_corr = polychoric_corr(data['satisfaction'], data[col])\n",
    "    correlation.append(r_corr[0])\n",
    "\n",
    "# Convert correlations to a pandas DataFrame\n",
    "correlation_df = pd.DataFrame({\n",
    "    'Variable': columns_of_interest,\n",
    "    'Polychoric_Correlation': correlation\n",
    "})\n",
    "\n",
    "# Calculate the sum of the polychoric correlations\n",
    "sum_polychoric_correlations = correlation_df['Polychoric_Correlation'].sum()\n",
    "\n",
    "# Calculate the percentage of each polychoric correlation\n",
    "correlation_df['Polychoric_Corr_Percent'] = (correlation_df['Polychoric_Correlation'] / sum_polychoric_correlations).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make variable column the index\n",
    "\n",
    "correlation_df.set_index('Variable', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pearson_Corr_%</th>\n",
       "      <th>Polychoric_Correlation</th>\n",
       "      <th>Polychoric_Corr_Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trust</th>\n",
       "      <td>0.133</td>\n",
       "      <td>0.325066</td>\n",
       "      <td>0.129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>impact</th>\n",
       "      <td>0.132</td>\n",
       "      <td>0.348443</td>\n",
       "      <td>0.138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>service</th>\n",
       "      <td>0.130</td>\n",
       "      <td>0.327699</td>\n",
       "      <td>0.130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>easy</th>\n",
       "      <td>0.111</td>\n",
       "      <td>0.273529</td>\n",
       "      <td>0.109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appealing</th>\n",
       "      <td>0.108</td>\n",
       "      <td>0.266616</td>\n",
       "      <td>0.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rewarding</th>\n",
       "      <td>0.101</td>\n",
       "      <td>0.255609</td>\n",
       "      <td>0.101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>build</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.249185</td>\n",
       "      <td>0.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>differs</th>\n",
       "      <td>0.096</td>\n",
       "      <td>0.251008</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>popular</th>\n",
       "      <td>0.089</td>\n",
       "      <td>0.223711</td>\n",
       "      <td>0.089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Pearson_Corr_%  Polychoric_Correlation  Polychoric_Corr_Percent\n",
       "trust               0.133                0.325066                    0.129\n",
       "impact              0.132                0.348443                    0.138\n",
       "service             0.130                0.327699                    0.130\n",
       "easy                0.111                0.273529                    0.109\n",
       "appealing           0.108                0.266616                    0.106\n",
       "rewarding           0.101                0.255609                    0.101\n",
       "build               0.100                0.249185                    0.099\n",
       "differs             0.096                0.251008                    0.100\n",
       "popular             0.089                0.223711                    0.089"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge correlation_df with correlations\n",
    "\n",
    "correlations = correlations.merge(correlation_df, left_index=True, right_index=True)\n",
    "\n",
    "correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardized Multiple Regression Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the data\n",
    "\n",
    "scaler.fit(data.drop(['id', 'brand', 'satisfaction'], axis=1))\n",
    "\n",
    "# Transform the data\n",
    "\n",
    "scaled_data = scaler.transform(data.drop(['id', 'brand', 'satisfaction'], axis=1))\n",
    "\n",
    "# Convert the scaled data to a DataFrame\n",
    "\n",
    "scaled_data = pd.DataFrame(scaled_data, columns=data.drop(['id', 'brand', 'satisfaction'], axis=1).columns)\n",
    "\n",
    "# Add the 'satisfaction' column to the scaled data\n",
    "\n",
    "scaled_data['satisfaction'] = data['satisfaction']\n",
    "\n",
    "# Initialize the LinearRegression model\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model to the scaled data\n",
    "\n",
    "model.fit(scaled_data.drop('satisfaction', axis=1), scaled_data['satisfaction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations['Std_Coefficients'] = coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trust</th>\n",
       "      <th>build</th>\n",
       "      <th>differs</th>\n",
       "      <th>easy</th>\n",
       "      <th>appealing</th>\n",
       "      <th>rewarding</th>\n",
       "      <th>popular</th>\n",
       "      <th>service</th>\n",
       "      <th>impact</th>\n",
       "      <th>satisfaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.905357</td>\n",
       "      <td>-0.926325</td>\n",
       "      <td>1.410483</td>\n",
       "      <td>0.929981</td>\n",
       "      <td>1.102790</td>\n",
       "      <td>-0.906791</td>\n",
       "      <td>-1.075291</td>\n",
       "      <td>1.067700</td>\n",
       "      <td>-0.703371</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.104536</td>\n",
       "      <td>-0.926325</td>\n",
       "      <td>-0.708977</td>\n",
       "      <td>-1.075291</td>\n",
       "      <td>-0.906791</td>\n",
       "      <td>-0.906791</td>\n",
       "      <td>-1.075291</td>\n",
       "      <td>-0.936593</td>\n",
       "      <td>-0.703371</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.905357</td>\n",
       "      <td>-0.926325</td>\n",
       "      <td>-0.708977</td>\n",
       "      <td>0.929981</td>\n",
       "      <td>1.102790</td>\n",
       "      <td>1.102790</td>\n",
       "      <td>-1.075291</td>\n",
       "      <td>1.067700</td>\n",
       "      <td>1.421725</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.104536</td>\n",
       "      <td>-0.926325</td>\n",
       "      <td>-0.708977</td>\n",
       "      <td>-1.075291</td>\n",
       "      <td>1.102790</td>\n",
       "      <td>-0.906791</td>\n",
       "      <td>0.929981</td>\n",
       "      <td>1.067700</td>\n",
       "      <td>1.421725</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.905357</td>\n",
       "      <td>1.079534</td>\n",
       "      <td>1.410483</td>\n",
       "      <td>0.929981</td>\n",
       "      <td>1.102790</td>\n",
       "      <td>1.102790</td>\n",
       "      <td>0.929981</td>\n",
       "      <td>1.067700</td>\n",
       "      <td>1.421725</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      trust     build   differs      easy  appealing  rewarding   popular  \\\n",
       "0  0.905357 -0.926325  1.410483  0.929981   1.102790  -0.906791 -1.075291   \n",
       "1 -1.104536 -0.926325 -0.708977 -1.075291  -0.906791  -0.906791 -1.075291   \n",
       "2  0.905357 -0.926325 -0.708977  0.929981   1.102790   1.102790 -1.075291   \n",
       "3 -1.104536 -0.926325 -0.708977 -1.075291   1.102790  -0.906791  0.929981   \n",
       "4  0.905357  1.079534  1.410483  0.929981   1.102790   1.102790  0.929981   \n",
       "\n",
       "    service    impact  satisfaction  \n",
       "0  1.067700 -0.703371             3  \n",
       "1 -0.936593 -0.703371             5  \n",
       "2  1.067700  1.421725             3  \n",
       "3  1.067700  1.421725             1  \n",
       "4  1.067700  1.421725             4  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trust</th>\n",
       "      <td>1.000196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>build</th>\n",
       "      <td>1.000196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>differs</th>\n",
       "      <td>1.000196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>easy</th>\n",
       "      <td>1.000196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appealing</th>\n",
       "      <td>1.000196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rewarding</th>\n",
       "      <td>1.000196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>popular</th>\n",
       "      <td>1.000196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>service</th>\n",
       "      <td>1.000196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>impact</th>\n",
       "      <td>1.000196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>satisfaction</th>\n",
       "      <td>1.172006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0\n",
       "trust         1.000196\n",
       "build         1.000196\n",
       "differs       1.000196\n",
       "easy          1.000196\n",
       "appealing     1.000196\n",
       "rewarding     1.000196\n",
       "popular       1.000196\n",
       "service       1.000196\n",
       "impact        1.000196\n",
       "satisfaction  1.172006"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get standard deviation of each column in scaled_data\n",
    "\n",
    "std_dev = scaled_data.std()\n",
    "\n",
    "std_dev = pd.DataFrame(std_dev)\n",
    "\n",
    "std_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1720059326669825"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat = std_dev.iloc[-1,-1]\n",
    "\n",
    "sat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop satisfaction from std_dev\n",
    "\n",
    "std_dev = std_dev.drop('satisfaction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Standard_Deviation</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trust</th>\n",
       "      <td>1.000196</td>\n",
       "      <td>0.135635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>build</th>\n",
       "      <td>1.000196</td>\n",
       "      <td>0.023411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>differs</th>\n",
       "      <td>1.000196</td>\n",
       "      <td>0.032631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>easy</th>\n",
       "      <td>1.000196</td>\n",
       "      <td>0.025744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appealing</th>\n",
       "      <td>1.000196</td>\n",
       "      <td>0.039647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rewarding</th>\n",
       "      <td>1.000196</td>\n",
       "      <td>0.005937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>popular</th>\n",
       "      <td>1.000196</td>\n",
       "      <td>0.019470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>service</th>\n",
       "      <td>1.000196</td>\n",
       "      <td>0.103573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>impact</th>\n",
       "      <td>1.000196</td>\n",
       "      <td>0.150482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Standard_Deviation  Coefficient\n",
       "trust                1.000196     0.135635\n",
       "build                1.000196     0.023411\n",
       "differs              1.000196     0.032631\n",
       "easy                 1.000196     0.025744\n",
       "appealing            1.000196     0.039647\n",
       "rewarding            1.000196     0.005937\n",
       "popular              1.000196     0.019470\n",
       "service              1.000196     0.103573\n",
       "impact               1.000196     0.150482"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add coefficients to std_dev DataFrame\n",
    "\n",
    "\n",
    "\n",
    "std_dev = std_dev.rename(columns={0: 'Standard_Deviation'})\n",
    "\n",
    "std_dev['Coefficient'] = coefficients\n",
    "\n",
    "std_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Standard_Deviation</th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Std_Coef</th>\n",
       "      <th>Std_Coef_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trust</th>\n",
       "      <td>1.000196</td>\n",
       "      <td>0.135635</td>\n",
       "      <td>0.115752</td>\n",
       "      <td>0.253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>build</th>\n",
       "      <td>1.000196</td>\n",
       "      <td>0.023411</td>\n",
       "      <td>0.019979</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>differs</th>\n",
       "      <td>1.000196</td>\n",
       "      <td>0.032631</td>\n",
       "      <td>0.027847</td>\n",
       "      <td>0.061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>easy</th>\n",
       "      <td>1.000196</td>\n",
       "      <td>0.025744</td>\n",
       "      <td>0.021970</td>\n",
       "      <td>0.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appealing</th>\n",
       "      <td>1.000196</td>\n",
       "      <td>0.039647</td>\n",
       "      <td>0.033835</td>\n",
       "      <td>0.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rewarding</th>\n",
       "      <td>1.000196</td>\n",
       "      <td>0.005937</td>\n",
       "      <td>0.005067</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>popular</th>\n",
       "      <td>1.000196</td>\n",
       "      <td>0.019470</td>\n",
       "      <td>0.016616</td>\n",
       "      <td>0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>service</th>\n",
       "      <td>1.000196</td>\n",
       "      <td>0.103573</td>\n",
       "      <td>0.088390</td>\n",
       "      <td>0.193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>impact</th>\n",
       "      <td>1.000196</td>\n",
       "      <td>0.150482</td>\n",
       "      <td>0.128422</td>\n",
       "      <td>0.280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Standard_Deviation  Coefficient  Std_Coef  Std_Coef_%\n",
       "trust                1.000196     0.135635  0.115752       0.253\n",
       "build                1.000196     0.023411  0.019979       0.044\n",
       "differs              1.000196     0.032631  0.027847       0.061\n",
       "easy                 1.000196     0.025744  0.021970       0.048\n",
       "appealing            1.000196     0.039647  0.033835       0.074\n",
       "rewarding            1.000196     0.005937  0.005067       0.011\n",
       "popular              1.000196     0.019470  0.016616       0.036\n",
       "service              1.000196     0.103573  0.088390       0.193\n",
       "impact               1.000196     0.150482  0.128422       0.280"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_dev['Std_Coef'] = std_dev['Coefficient'] * std_dev['Standard_Deviation'] / sat\n",
    "\n",
    "std_dev['Std_Coef_%'] = round(std_dev['Std_Coef'] / std_dev['Std_Coef'].sum(), 3)\n",
    "\n",
    "std_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pearson_Corr_%</th>\n",
       "      <th>Polychoric_Correlation</th>\n",
       "      <th>Polychoric_Corr_Percent</th>\n",
       "      <th>Std_Coefficients</th>\n",
       "      <th>Standard_Deviation</th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Std_Coef</th>\n",
       "      <th>Std_Coef_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trust</th>\n",
       "      <td>0.133</td>\n",
       "      <td>0.325066</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.135635</td>\n",
       "      <td>1.000196</td>\n",
       "      <td>0.135635</td>\n",
       "      <td>0.115752</td>\n",
       "      <td>0.253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>impact</th>\n",
       "      <td>0.132</td>\n",
       "      <td>0.348443</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.023411</td>\n",
       "      <td>1.000196</td>\n",
       "      <td>0.150482</td>\n",
       "      <td>0.128422</td>\n",
       "      <td>0.280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>service</th>\n",
       "      <td>0.130</td>\n",
       "      <td>0.327699</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.032631</td>\n",
       "      <td>1.000196</td>\n",
       "      <td>0.103573</td>\n",
       "      <td>0.088390</td>\n",
       "      <td>0.193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>easy</th>\n",
       "      <td>0.111</td>\n",
       "      <td>0.273529</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.025744</td>\n",
       "      <td>1.000196</td>\n",
       "      <td>0.025744</td>\n",
       "      <td>0.021970</td>\n",
       "      <td>0.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appealing</th>\n",
       "      <td>0.108</td>\n",
       "      <td>0.266616</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.039647</td>\n",
       "      <td>1.000196</td>\n",
       "      <td>0.039647</td>\n",
       "      <td>0.033835</td>\n",
       "      <td>0.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rewarding</th>\n",
       "      <td>0.101</td>\n",
       "      <td>0.255609</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.005937</td>\n",
       "      <td>1.000196</td>\n",
       "      <td>0.005937</td>\n",
       "      <td>0.005067</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>build</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.249185</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.019470</td>\n",
       "      <td>1.000196</td>\n",
       "      <td>0.023411</td>\n",
       "      <td>0.019979</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>differs</th>\n",
       "      <td>0.096</td>\n",
       "      <td>0.251008</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.103573</td>\n",
       "      <td>1.000196</td>\n",
       "      <td>0.032631</td>\n",
       "      <td>0.027847</td>\n",
       "      <td>0.061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>popular</th>\n",
       "      <td>0.089</td>\n",
       "      <td>0.223711</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.150482</td>\n",
       "      <td>1.000196</td>\n",
       "      <td>0.019470</td>\n",
       "      <td>0.016616</td>\n",
       "      <td>0.036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Pearson_Corr_%  Polychoric_Correlation  Polychoric_Corr_Percent  \\\n",
       "trust               0.133                0.325066                    0.129   \n",
       "impact              0.132                0.348443                    0.138   \n",
       "service             0.130                0.327699                    0.130   \n",
       "easy                0.111                0.273529                    0.109   \n",
       "appealing           0.108                0.266616                    0.106   \n",
       "rewarding           0.101                0.255609                    0.101   \n",
       "build               0.100                0.249185                    0.099   \n",
       "differs             0.096                0.251008                    0.100   \n",
       "popular             0.089                0.223711                    0.089   \n",
       "\n",
       "           Std_Coefficients  Standard_Deviation  Coefficient  Std_Coef  \\\n",
       "trust              0.135635            1.000196     0.135635  0.115752   \n",
       "impact             0.023411            1.000196     0.150482  0.128422   \n",
       "service            0.032631            1.000196     0.103573  0.088390   \n",
       "easy               0.025744            1.000196     0.025744  0.021970   \n",
       "appealing          0.039647            1.000196     0.039647  0.033835   \n",
       "rewarding          0.005937            1.000196     0.005937  0.005067   \n",
       "build              0.019470            1.000196     0.023411  0.019979   \n",
       "differs            0.103573            1.000196     0.032631  0.027847   \n",
       "popular            0.150482            1.000196     0.019470  0.016616   \n",
       "\n",
       "           Std_Coef_%  \n",
       "trust           0.253  \n",
       "impact          0.280  \n",
       "service         0.193  \n",
       "easy            0.048  \n",
       "appealing       0.074  \n",
       "rewarding       0.011  \n",
       "build           0.044  \n",
       "differs         0.061  \n",
       "popular         0.036  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge std_dev with correlations\n",
    "\n",
    "correlations = correlations.merge(std_dev, left_index=True, right_index=True)\n",
    "\n",
    "correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shapley Values for Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['brand', 'id', 'satisfaction', 'trust', 'build', 'differs', 'easy',\n",
       "       'appealing', 'rewarding', 'popular', 'service', 'impact'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trust',\n",
       " 'build',\n",
       " 'differs',\n",
       " 'easy',\n",
       " 'appealing',\n",
       " 'rewarding',\n",
       " 'popular',\n",
       " 'service',\n",
       " 'impact']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_of_interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Load dataset\n",
    "\n",
    "X = data[['trust', 'build', 'differs', 'easy',\n",
    "       'appealing', 'rewarding', 'popular', 'service', 'impact']]\n",
    "y = data['satisfaction']\n",
    "\n",
    "# Train a model\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The feature_perturbation option is now deprecated in favor of using the appropriate masker (maskers.Independent, or maskers.Impute)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x510 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import shap\n",
    "\n",
    "# Initialize SHAP explainer\n",
    "explainer = shap.LinearExplainer(model, X, feature_perturbation=\"interventional\")\n",
    "\n",
    "# Calculate Shapley values\n",
    "shap_values = explainer.shap_values(X)\n",
    "\n",
    "# Plot the summary\n",
    "shap.summary_plot(shap_values, X, plot_type=\"bar\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = pd.DataFrame(shap_values, columns=columns_of_interest)\n",
    "\n",
    "# mean of absolute values of each column\n",
    "\n",
    "shap_values_avg = shap_values.abs().mean()\n",
    "\n",
    "shap_values_avg = pd.DataFrame(shap_values_avg)\n",
    "\n",
    "shap_values_avg = shap_values_avg.rename(columns={0: 'Shapley_Value'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = correlations.merge(shap_values_avg, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pearson_Corr_%</th>\n",
       "      <th>Polychoric_Correlation</th>\n",
       "      <th>Polychoric_Corr_Percent</th>\n",
       "      <th>Std_Coefficients</th>\n",
       "      <th>Standard_Deviation</th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Std_Coef</th>\n",
       "      <th>Std_Coef_%</th>\n",
       "      <th>Shapley_Value</th>\n",
       "      <th>Shapley_Value_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trust</th>\n",
       "      <td>0.133</td>\n",
       "      <td>0.325066</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.135635</td>\n",
       "      <td>1.000196</td>\n",
       "      <td>0.135635</td>\n",
       "      <td>0.115752</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.136576</td>\n",
       "      <td>0.267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>impact</th>\n",
       "      <td>0.132</td>\n",
       "      <td>0.348443</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.023411</td>\n",
       "      <td>1.000196</td>\n",
       "      <td>0.150482</td>\n",
       "      <td>0.128422</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.130708</td>\n",
       "      <td>0.255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>service</th>\n",
       "      <td>0.130</td>\n",
       "      <td>0.327699</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.032631</td>\n",
       "      <td>1.000196</td>\n",
       "      <td>0.103573</td>\n",
       "      <td>0.088390</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.102030</td>\n",
       "      <td>0.199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>easy</th>\n",
       "      <td>0.111</td>\n",
       "      <td>0.273529</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.025744</td>\n",
       "      <td>1.000196</td>\n",
       "      <td>0.025744</td>\n",
       "      <td>0.021970</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.025924</td>\n",
       "      <td>0.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appealing</th>\n",
       "      <td>0.108</td>\n",
       "      <td>0.266616</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.039647</td>\n",
       "      <td>1.000196</td>\n",
       "      <td>0.039647</td>\n",
       "      <td>0.033835</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.039060</td>\n",
       "      <td>0.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rewarding</th>\n",
       "      <td>0.101</td>\n",
       "      <td>0.255609</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.005937</td>\n",
       "      <td>1.000196</td>\n",
       "      <td>0.005937</td>\n",
       "      <td>0.005067</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.005861</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>build</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.249185</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.019470</td>\n",
       "      <td>1.000196</td>\n",
       "      <td>0.023411</td>\n",
       "      <td>0.019979</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.023157</td>\n",
       "      <td>0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>differs</th>\n",
       "      <td>0.096</td>\n",
       "      <td>0.251008</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.103573</td>\n",
       "      <td>1.000196</td>\n",
       "      <td>0.032631</td>\n",
       "      <td>0.027847</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.028857</td>\n",
       "      <td>0.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>popular</th>\n",
       "      <td>0.089</td>\n",
       "      <td>0.223711</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.150482</td>\n",
       "      <td>1.000196</td>\n",
       "      <td>0.019470</td>\n",
       "      <td>0.016616</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.019465</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Pearson_Corr_%  Polychoric_Correlation  Polychoric_Corr_Percent  \\\n",
       "trust               0.133                0.325066                    0.129   \n",
       "impact              0.132                0.348443                    0.138   \n",
       "service             0.130                0.327699                    0.130   \n",
       "easy                0.111                0.273529                    0.109   \n",
       "appealing           0.108                0.266616                    0.106   \n",
       "rewarding           0.101                0.255609                    0.101   \n",
       "build               0.100                0.249185                    0.099   \n",
       "differs             0.096                0.251008                    0.100   \n",
       "popular             0.089                0.223711                    0.089   \n",
       "\n",
       "           Std_Coefficients  Standard_Deviation  Coefficient  Std_Coef  \\\n",
       "trust              0.135635            1.000196     0.135635  0.115752   \n",
       "impact             0.023411            1.000196     0.150482  0.128422   \n",
       "service            0.032631            1.000196     0.103573  0.088390   \n",
       "easy               0.025744            1.000196     0.025744  0.021970   \n",
       "appealing          0.039647            1.000196     0.039647  0.033835   \n",
       "rewarding          0.005937            1.000196     0.005937  0.005067   \n",
       "build              0.019470            1.000196     0.023411  0.019979   \n",
       "differs            0.103573            1.000196     0.032631  0.027847   \n",
       "popular            0.150482            1.000196     0.019470  0.016616   \n",
       "\n",
       "           Std_Coef_%  Shapley_Value  Shapley_Value_%  \n",
       "trust           0.253       0.136576            0.267  \n",
       "impact          0.280       0.130708            0.255  \n",
       "service         0.193       0.102030            0.199  \n",
       "easy            0.048       0.025924            0.051  \n",
       "appealing       0.074       0.039060            0.076  \n",
       "rewarding       0.011       0.005861            0.011  \n",
       "build           0.044       0.023157            0.045  \n",
       "differs         0.061       0.028857            0.056  \n",
       "popular         0.036       0.019465            0.038  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations['Shapley_Value_%'] = round(correlations['Shapley_Value'] / correlations['Shapley_Value'].sum(), 3)\n",
    "\n",
    "correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Johnson's Epilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from scipy.stats import johnsonsu\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "# Specify the predictor variables and the target variable\n",
    "predictors = ['trust', 'build', 'differs', 'easy', 'appealing', 'rewarding', 'popular', 'service', 'impact']\n",
    "target = 'satisfaction'\n",
    "\n",
    "# Fit Johnson SU distribution to each predictor\n",
    "johnson_params = {}\n",
    "for col in predictors:\n",
    "    params = johnsonsu.fit(data[col])\n",
    "    johnson_params[col] = params\n",
    "\n",
    "# Transform predictors using the fitted Johnson SU parameters\n",
    "X_transformed = pd.DataFrame()\n",
    "for col in predictors:\n",
    "    gamma, delta, xi, lambda_ = johnson_params[col]\n",
    "    transformed = johnsonsu.cdf(data[col], gamma, delta, xi, lambda_)\n",
    "    X_transformed[col] = transformed\n",
    "\n",
    "# Fit the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_transformed, data[target])\n",
    "\n",
    "# Display the model coefficients\n",
    "johnson_coef = pd.DataFrame({\n",
    "    'Predictor': predictors,\n",
    "    'Johnson_Epsilon': model.coef_\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "johnson_coef = pd.DataFrame(johnson_coef)\n",
    "\n",
    "johnson_coef.set_index('Predictor', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "johnson_coef['Johnson_Epsilon_%'] = round(johnson_coef['Johnson_Epsilon'] / johnson_coef['Johnson_Epsilon'].sum(), 3)\n",
    "\n",
    "correlations = correlations.merge(johnson_coef, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pearson_Corr</th>\n",
       "      <th>Pearson_Corr_%</th>\n",
       "      <th>Polychoric_Correlation</th>\n",
       "      <th>Polychoric_Corr_Percent</th>\n",
       "      <th>Standard_Deviation</th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Std_Coef</th>\n",
       "      <th>Std_Coef_%</th>\n",
       "      <th>Shapley_Value</th>\n",
       "      <th>Shapley_Value_%</th>\n",
       "      <th>Johnson_Epsilon</th>\n",
       "      <th>Johnson_Epsilon_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trust</th>\n",
       "      <td>0.255706</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.325066</td>\n",
       "      <td>0.129</td>\n",
       "      <td>1.000196</td>\n",
       "      <td>0.135635</td>\n",
       "      <td>0.115752</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.126132</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.381407</td>\n",
       "      <td>0.253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>impact</th>\n",
       "      <td>0.254539</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.348443</td>\n",
       "      <td>0.138</td>\n",
       "      <td>1.000196</td>\n",
       "      <td>0.150482</td>\n",
       "      <td>0.128422</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.162314</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.403438</td>\n",
       "      <td>0.268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>service</th>\n",
       "      <td>0.251098</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.327699</td>\n",
       "      <td>0.130</td>\n",
       "      <td>1.000196</td>\n",
       "      <td>0.103573</td>\n",
       "      <td>0.088390</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.121793</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.399815</td>\n",
       "      <td>0.265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>easy</th>\n",
       "      <td>0.212985</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.273529</td>\n",
       "      <td>0.109</td>\n",
       "      <td>1.000196</td>\n",
       "      <td>0.025744</td>\n",
       "      <td>0.021970</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.050894</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.052695</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appealing</th>\n",
       "      <td>0.207997</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.266616</td>\n",
       "      <td>0.106</td>\n",
       "      <td>1.000196</td>\n",
       "      <td>0.039647</td>\n",
       "      <td>0.033835</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.068315</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.095863</td>\n",
       "      <td>0.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rewarding</th>\n",
       "      <td>0.194561</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.255609</td>\n",
       "      <td>0.101</td>\n",
       "      <td>1.000196</td>\n",
       "      <td>0.005937</td>\n",
       "      <td>0.005067</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.047909</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.012569</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>build</th>\n",
       "      <td>0.191896</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.249185</td>\n",
       "      <td>0.099</td>\n",
       "      <td>1.000196</td>\n",
       "      <td>0.023411</td>\n",
       "      <td>0.019979</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.064744</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.049673</td>\n",
       "      <td>0.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>differs</th>\n",
       "      <td>0.184801</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.251008</td>\n",
       "      <td>0.100</td>\n",
       "      <td>1.000196</td>\n",
       "      <td>0.032631</td>\n",
       "      <td>0.027847</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.055374</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.070583</td>\n",
       "      <td>0.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>popular</th>\n",
       "      <td>0.171425</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.223711</td>\n",
       "      <td>0.089</td>\n",
       "      <td>1.000196</td>\n",
       "      <td>0.019470</td>\n",
       "      <td>0.016616</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.051395</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.039853</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Pearson_Corr  Pearson_Corr_%  Polychoric_Correlation  \\\n",
       "trust          0.255706           0.133                0.325066   \n",
       "impact         0.254539           0.132                0.348443   \n",
       "service        0.251098           0.130                0.327699   \n",
       "easy           0.212985           0.111                0.273529   \n",
       "appealing      0.207997           0.108                0.266616   \n",
       "rewarding      0.194561           0.101                0.255609   \n",
       "build          0.191896           0.100                0.249185   \n",
       "differs        0.184801           0.096                0.251008   \n",
       "popular        0.171425           0.089                0.223711   \n",
       "\n",
       "           Polychoric_Corr_Percent  Standard_Deviation  Coefficient  Std_Coef  \\\n",
       "trust                        0.129            1.000196     0.135635  0.115752   \n",
       "impact                       0.138            1.000196     0.150482  0.128422   \n",
       "service                      0.130            1.000196     0.103573  0.088390   \n",
       "easy                         0.109            1.000196     0.025744  0.021970   \n",
       "appealing                    0.106            1.000196     0.039647  0.033835   \n",
       "rewarding                    0.101            1.000196     0.005937  0.005067   \n",
       "build                        0.099            1.000196     0.023411  0.019979   \n",
       "differs                      0.100            1.000196     0.032631  0.027847   \n",
       "popular                      0.089            1.000196     0.019470  0.016616   \n",
       "\n",
       "           Std_Coef_%  Shapley_Value  Shapley_Value_%  Johnson_Epsilon  \\\n",
       "trust           0.253       0.126132            0.168         0.381407   \n",
       "impact          0.280       0.162314            0.217         0.403438   \n",
       "service         0.193       0.121793            0.163         0.399815   \n",
       "easy            0.048       0.050894            0.068         0.052695   \n",
       "appealing       0.074       0.068315            0.091         0.095863   \n",
       "rewarding       0.011       0.047909            0.064         0.012569   \n",
       "build           0.044       0.064744            0.086         0.049673   \n",
       "differs         0.061       0.055374            0.074         0.070583   \n",
       "popular         0.036       0.051395            0.069         0.039853   \n",
       "\n",
       "           Johnson_Epsilon_%  \n",
       "trust                  0.253  \n",
       "impact                 0.268  \n",
       "service                0.265  \n",
       "easy                   0.035  \n",
       "appealing              0.064  \n",
       "rewarding              0.008  \n",
       "build                  0.033  \n",
       "differs                0.047  \n",
       "popular                0.026  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Decrease in RF Gini Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Feature  Gini Importance\n",
      "6    popular         0.135187\n",
      "1      build         0.123719\n",
      "5  rewarding         0.118519\n",
      "2    differs         0.114670\n",
      "3       easy         0.112496\n",
      "4  appealing         0.107000\n",
      "7    service         0.105882\n",
      "8     impact         0.092704\n",
      "0      trust         0.089825\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(data[columns_of_interest], data['satisfaction'])\n",
    "\n",
    "gini_importance = model.feature_importances_\n",
    "\n",
    "# Create a DataFrame for better readability\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': columns_of_interest,\n",
    "    'Gini Importance': gini_importance\n",
    "})\n",
    "\n",
    "# Sort the features by importance\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Gini Importance', ascending=False)\n",
    "\n",
    "# Display the feature importances\n",
    "print(feature_importance_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
