---
title: "A Replication of Karlan and List (2007)"
author: "Nick Shuckerow"
date: today
callout-appearance: minimal # this hides the blue "i" icon on .callout-notes
---


## Introduction

Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the _American Economic Review_ in 2007. The article and supporting data are available from the [AEA website](https://www.aeaweb.org/articles?id=10.1257/aer.97.5.1774) and from Innovations for Poverty Action as part of [Harvard's Dataverse](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/27853&version=4.2).

The experiment was conducted through a direct mail campaign for a liberal nonprofit organization. The authors assigned 67% of the 50,000 to the treatment group and 33% to the control group.

The letters sent to the treatment and control group were the same except in the following regards:

- The treatment group letter had an additional paragraph saying that their donation will be matched.
- The reply card for the treatment group had details on the matching grant.


The letters were randomized through 3 different dimensions.

1. matching price ratio
2. maximum match amount
3. suggested donation amount

The experiment found that using matching donations increases the revenue per solicitation and the probability that someone donates. 

It also found that larger match ratios relative to smaller match ratios have no additional impact. 
This project seeks to replicate their results.

Overall, the authors found a unique way to measure the scope of a public good (donations) in a real world setting, rather than hypothetical scenarios. This is a valuable contribution to the literature on charitable giving and public goods.

## Data

### Description

The dataset seen below which Karlan and List gathered on the 50,083 subjects has over 52 columns or variables. The main ones are concerned about for our research are 'gave' (if the individual donated any amount), 'amount' (what amount they donated), 'treatment' (if they were a part of the treatment or control group), and 'ratio' (matching ratio given to that subject).

Many of the columns are redundant (treatmeant vs control columns, ratio columns vs ratio1, ratio2, ratio3 columns), however they allow us to more easily filter the data and make calculations.

In the second cell, you can see the description of variables 'treatment' and 'control'. Through this, it is shown that 66% of the participants were a part of the treatment group, and 33% were a part of the control group.

Since many of these variables are binary, a 1 or 0 is used to describe whether the participant had that treatment, variables, or attribute, which allows analysts to easily calculate proportions or percentages like with treatment and control.

```{python}
import pandas as pd
karlan = pd.read_stata("karlan_list_2007.dta")
karlan
```
:::: {.callout-note collapse="true"}

```{python}
karlan.describe()
```

### Variable Definitions

| Variable             | Description                                                         |
|----------------------|---------------------------------------------------------------------|
| `treatment`          | Treatment                                                           |
| `control`            | Control                                                             |
| `ratio`              | Match ratio                                                         |
| `ratio2`             | 2:1 match ratio                                                     |
| `ratio3`             | 3:1 match ratio                                                     |
| `size`               | Match threshold                                                     |
| `size25`             | \$25,000 match threshold                                            |
| `size50`             | \$50,000 match threshold                                            |
| `size100`            | \$100,000 match threshold                                           |
| `sizeno`             | Unstated match threshold                                            |
| `ask`                | Suggested donation amount                                           |
| `askd1`              | Suggested donation was highest previous contribution                |
| `askd2`              | Suggested donation was 1.25 x highest previous contribution         |
| `askd3`              | Suggested donation was 1.50 x highest previous contribution         |
| `ask1`               | Highest previous contribution (for suggestion)                      |
| `ask2`               | 1.25 x highest previous contribution (for suggestion)               |
| `ask3`               | 1.50 x highest previous contribution (for suggestion)               |
| `amount`             | Dollars given                                                       |
| `gave`               | Gave anything                                                       |
| `amountchange`       | Change in amount given                                              |
| `hpa`                | Highest previous contribution                                       |
| `ltmedmra`           | Small prior donor: last gift was less than median \$35              |
| `freq`               | Number of prior donations                                           |
| `years`              | Number of years since initial donation                              |
| `year5`              | At least 5 years since initial donation                             |
| `mrm2`               | Number of months since last donation                                |
| `dormant`            | Already donated in 2005                                             |
| `female`             | Female                                                              |
| `couple`             | Couple                                                              |
| `state50one`         | State tag: 1 for one observation of each of 50 states; 0 otherwise  |
| `nonlit`             | Nonlitigation                                                       |
| `cases`              | Court cases from state in 2004-5 in which organization was involved |
| `statecnt`           | Percent of sample from state                                        |
| `stateresponse`      | Proportion of sample from the state who gave                        |
| `stateresponset`     | Proportion of treated sample from the state who gave                |
| `stateresponsec`     | Proportion of control sample from the state who gave                |
| `stateresponsetminc` | stateresponset - stateresponsec                                     |
| `perbush`            | State vote share for Bush                                           |
| `close25`            | State vote share for Bush between 47.5% and 52.5%                   |
| `red0`               | Red state                                                           |
| `blue0`              | Blue state                                                          |
| `redcty`             | Red county                                                          |
| `bluecty`            | Blue county                                                         |
| `pwhite`             | Proportion white within zip code                                    |
| `pblack`             | Proportion black within zip code                                    |
| `page18_39`          | Proportion age 18-39 within zip code                                |
| `ave_hh_sz`          | Average household size within zip code                              |
| `median_hhincome`    | Median household income within zip code                             |
| `powner`             | Proportion house owner within zip code                              |
| `psch_atlstba`       | Proportion who finished college within zip code                     |
| `pop_propurban`      | Proportion of population urban within zip code                      |

::::


### Balance Test 

As an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.

<!--_todo: test a few variables other than the key outcome variables (for example, test months since last donation) to see if the treatment and control groups are statistically significantly different at the 95% confidence level. Do each as a t-test and separately as a linear regression, and confirm you get the exact same results from both methods. When doing a t-test, use the formula in the class slides. When doing the linear regression, regress for example mrm2 on treatment and look at the estimated coefficient on the treatment variable. It might be helpful to compare parts of your analysis to Table 1 in the paper. Be sure to comment on your results (hint: why is Table 1 included in the paper)._ -->

#### Months since last Donation Variable
```{python}
# Months since last donation t-test

mrm2_treat = karlan[karlan['treatment'] == 1]['mrm2']
mrm2_control = karlan[karlan['treatment'] == 0]['mrm2']

mrm2_t_mean = mrm2_treat.mean()
mrm2_c_mean = mrm2_control.mean()

mrm2_t_std = mrm2_treat.std()
mrm2_c_std = mrm2_control.std()

mrm2_t_n = mrm2_treat.count()
mrm2_c_n = mrm2_control.count()

t_mrm2 = (mrm2_t_mean - mrm2_c_mean) / ((mrm2_t_std**2/mrm2_t_n) + (mrm2_c_std**2/mrm2_c_n))**0.5

print(t_mrm2)
```

```{python}
# calculate p-value
from scipy import stats

p_mrm2 = stats.t.sf(abs(t_mrm2), mrm2_t_n + mrm2_c_n - 2) * 2
print(p_mrm2)

# Not statistically significant
```

```{python}
# Linear Regression - mrm2

import pyrsm as rsm

lr_mrm2 = rsm.regress(
    data = karlan[['treatment', 'mrm2']],
    evar = "treatment",
    rvar = "mrm2"
    )

lr_mrm2.summary()
```

#### Couple Variable
```{python}
couple_treat = karlan[karlan['treatment'] == 1]['couple']
couple_control = karlan[karlan['treatment'] == 0]['couple']

couple_t_mean = couple_treat.mean()
couple_c_mean = couple_control.mean()

couple_t_std = couple_treat.std()
couple_c_std = couple_control.std()

couple_t_n = couple_treat.count()
couple_c_n = couple_control.count()

t_couple = (couple_t_mean - couple_c_mean) / ((couple_t_std**2/couple_t_n) + (couple_c_std**2/couple_c_n))**0.5

print(t_couple)
```
```{python}
# calculate p-value

p_couple = stats.t.sf(abs(t_couple), couple_t_n + couple_c_n - 2) * 2
print(p_couple)

# Not statistically significant
```
```{python}
lr_couple = rsm.regress(
    data = karlan[['treatment', 'couple']],
    evar = "treatment",
    rvar = "couple"
    )

lr_couple.summary()
```

#### Balance Test Results

The intercept coefficients calculated for mrm2 and couple variables are exactly the same as in table 1 of the paper for the control group. Also, when incorporating the coefficients for treatment (treatment = 1), they also equal the mean values in table 1 for the treatment group.

For mrm2 (months since last donation), the control group mean was 12.998 and that increases to 13.012 if they were a part of the treatment group. This is not a large disparity and as such did not prove to be statistically significant on a 95% confidence interval.

For couple (whether the donor was a couple), the control group mean was 0.093 (interpreted as 9.3% of donors in the control group were couples) and that decreases to 0.091 if they were a part of the treatment group. This is also not a large disparity and as such did not prove to be statistically significant on a 95% confidence interval.

## Experimental Results

### Charitable Contribution Made

First, I analyze whether matched donations lead to an increased response rate of making a donation. 

<!--_todo: make a barplot with two bars. Each bar is the proportion of people who donated. One bar for treatment and one bar for control._ -->

```{python}
# find proportion of treatment group that gave money

treat_gave = karlan[karlan['treatment'] == 1]['gave'].mean()
control_gave = karlan[karlan['treatment'] == 0]['gave'].mean()

print(treat_gave, control_gave)
```

```{python}
# create bar graph for proportion of treatment/control group that gave money

import matplotlib.pyplot as plt

fig, ax = plt.subplots()
ax.bar(['Treatment', 'Control'], [treat_gave, control_gave])
ax.set_ylabel('Proportion of Group that Gave Money')
ax.set_title('Proportion of Treatment and Control Group that Gave Money')
plt.show()
```

<!--_todo: run a t-test between the treatment and control groups on the binary outcome of whether any charitable donation was made. Also run a bivariate linear regression that demonstrates the same finding. (It may help to confirm your calculations match Table 2a Panel A.) Report your statistical results and interpret them in the context of the experiment (e.g., if you found a difference with a small p-value or that was statistically significant at some threshold, what have you learned about human behavior? Use mostly English words, not numbers or stats, to explain your finding.)_-->

```{python}
# Calculate t-stat for those who donated if they were a part of treatment or control group

gave_treat = karlan[karlan['treatment'] == 1]['gave']
gave_control = karlan[karlan['treatment'] == 0]['gave']

gave_t_mean = gave_treat.mean()
gave_c_mean = gave_control.mean()

gave_t_std = gave_treat.std()
gave_c_std = gave_control.std()

gave_t_n = gave_treat.count()
gave_c_n = gave_control.count()

t_gave = (gave_t_mean - gave_c_mean) / ((gave_t_std**2/gave_t_n) + (gave_c_std**2/gave_c_n))**0.5

print(t_gave)
```

```{python}
# Calculate p-value on 95% confidence interval

p_gave = stats.t.sf(abs(t_gave), gave_t_n + gave_c_n - 2) * 2
p_gave

# Statistically significant
```

```{python}
# Run a linear regression which 'gave' is the response variable and 'treatment' is the explanatory variable

lr_gave = rsm.regress(
    data = karlan[['treatment', 'gave']],
    evar = "treatment",
    rvar = "gave"
    )

lr_gave.summary()
```

The outcome of our t-test and linear regression were both similar in that it was found at a 95% confidence interval that the treatment did cause an increase in the number of donations. The linear regression did not explain any variance in the data, however that is not as important because we are using what should be a logistic regression (binary outcome of 1 or 0 if they donated or not) with a linear regression model. 


<!--_todo: run a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable is assignment to treatment or control. Confirm that your results replicate Table 3 column 1 in the paper._-->

```{python}
# Run probit regression on gave and treatment variables

import statsmodels.formula.api as smf

mod = smf.probit('gave ~ treatment', data=karlan)
res = mod.fit()
res.summary()
```

### Differences between Match Rates

Next, I assess the effectiveness of different sizes of matched donations on the response rate.

#### Ratio of 1:1 vs Ratio of 2:1

```{python}
# Calculate t-stat for Ratio 1:1 vs Ratio 2:1

gave_ratio1 = karlan[karlan['ratio'] == 1]['gave']
gave_ratio2 = karlan[karlan['ratio'] == 2]['gave']

gave_1_mean = gave_ratio1.mean()
gave_2_mean = gave_ratio2.mean()

gave_1_std = gave_ratio1.std()
gave_2_std = gave_ratio2.std()

gave_1_n = gave_ratio1.count()
gave_2_n = gave_ratio2.count()

t_gave_ratio = (gave_2_mean - gave_1_mean) / ((gave_2_std**2/gave_2_n) + (gave_1_std**2/gave_1_n))**0.5

print(t_gave_ratio)
```

```{python}
p_gave_ratio = stats.t.sf(abs(t_gave_ratio), gave_2_n + gave_1_n - 2) * 2
p_gave_ratio

# Not statistically significant
```

#### Ratio of 2:1 vs Ratio of 3:1

```{python}
gave_ratio3 = karlan[karlan['ratio'] == 3]['gave']
gave_ratio2 = karlan[karlan['ratio'] == 2]['gave']

gave_3_mean = gave_ratio3.mean()
gave_2_mean = gave_ratio2.mean()

gave_3_std = gave_ratio3.std()
gave_2_std = gave_ratio2.std()

gave_3_n = gave_ratio3.count()
gave_2_n = gave_ratio2.count()

t_gave_ratio_23 = (gave_2_mean - gave_3_mean) / ((gave_2_std**2/gave_2_n) + (gave_3_std**2/gave_3_n))**0.5

print(t_gave_ratio_23)
```

```{python}
p_gave_ratio_23 = stats.t.sf(abs(t_gave_ratio_23), gave_2_n + gave_3_n - 2) * 2
p_gave_ratio_23

# Not statistically significant
```

The above calculations matches what Karlan suggests in his paper, that increasing the match ratio does not increase the probability of making a donation. The above calculations show a 1:1 match ratio when compared to a 2:1 match ratio, and a 2:1 match ratio when compared to a 3:1 match ratio. We did a two-sided t-test, which has a null hypothesis stating that 2:1 is not the same as 1:1, and 3:1 is not the same as 2:1. 

<!--_todo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the "figures suggest" comment the authors make on page 8?_-->

```{python}
#create a variable ratio1 where if ratio column equals 1, then ratio1 equlas 1, else 0

karlan['ratio1'] = karlan['ratio'].apply(lambda x: 1 if x == 1 else 0)
```

```{python}
# Linear regression for match ratios and treatment

lr_ratio = rsm.regress(
    data = karlan[['gave', 'ratio1', 'ratio2', 'ratio3']],
    evar = ['ratio1', 'ratio2', 'ratio3'],
    rvar = 'gave'
    )  

lr_ratio.summary()
```

The results of linear regression model on match ratios of 1:1, 2:1, and 3:1 show that all but a ratio of 1:1 are statistically significant. The intercept coefficient (meaning when there is no match) is 0.018, and then for ratio 1:1 it has a coefficient of 0.003, which added to 0.018 is 0.021. For ratio 2:1 and 3:1, they both have coefficients of 0.005, creating a response rate of 0.023 for both. All these response rates match table 2A in the paper.

The precision of these estimates also match what is in the paper for standard error. Each ratio has a standard error of 0.002, meaning that ratio 1:1 could have a varying effect on response rate between 0.001 and 0.005, and ratios 2:1 and 3:1 could vary between 0.003 and 0.007. All however remain positive when incorporating standard error, meaning that the match ratio does have a positive effect on response rate when comparing to control.

<!--_todo: Assess the same issue using a regression. Specifically, create the variable `ratio1` then regress `gave` on `ratio1`, `ratio2`, and `ratio3` (or alternatively, regress `gave` on the categorical variable `ratio`). Interpret the coefficients and their statistical precision._-->

<!--_todo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios.  Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?_-->


### Size of Charitable Contribution

In this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.

<!--_todo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis?_-->

```{python}
# Linear Regression on Treatment to Predict donation amount
lr_d_amount = rsm.regress(
    data = karlan[['amount', 'treatment']],
    evar = 'treatment',
    rvar = 'amount'
    )  

lr_d_amount.summary()
```

From our linear regression model to calculate dollars donated amount from whether the donor was in the treatment or control group, we can conclude that the control group donates $0.813 and being a part of the treatment group increases that amount by $0.154, bringing the estimated dollars donated amount to $0.967. Per a 95% confidence interval, the model is not statistically significant, however it is very close to being so.

```{python}
# Linear Regression on treatment to predict donation amounts above 0

lr_d_amount_above0 = rsm.regress(
    data = karlan[karlan['amount'] > 0][['amount', 'treatment']],
    evar = 'treatment',
    rvar = 'amount'
    )  

lr_d_amount_above0.summary()
```


After filtering the data to only include those who donated, the linear regression model changed significantly. The intercept coefficient is now $45.54, and the treatment coefficient is now negative $1.67. Now, the treatment group has a negative affect on amount donated, meaning that the control group donates $45.54 and the treatment group donates $43.87.

However, the model is not statistically significant at 95% confidence interval. 

<!--_todo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients -- what did we learn? Does the treatment coefficient have a causal interpretation?_--> 

<!--_todo: Make two plot: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot._-->

```{python}
# create a histogram for all the donation amounts above 0 for the control group

fig, ax = plt.subplots()
ax.hist(karlan[(karlan['amount'] > 0) & (karlan['treatment'] == 0)]['amount'], bins=25)
ax.axvline(43.87, color='red')
ax.text(43.87 + 1, ax.get_ylim()[1] * 0.9, f'{43.87}', color='red')
ax.set_ylabel('Frequency')
ax.set_xlabel('Donation Amount')
ax.set_title('Frequency of Donation Amounts for Control Group')
plt.show()


```

```{python}
# create a histogram for all the donation amounts above 0 for the treatment group

fig, ax = plt.subplots()
ax.hist(karlan[(karlan['amount'] > 0) & (karlan['treatment'] == 1)]['amount'], bins=25)
ax.axvline(45.54, color='red')
ax.text(45.54 + 1, ax.get_ylim()[1] * 0.9, f'{45.54}', color='red')
ax.set_ylabel('Frequency')
ax.set_xlabel('Donation Amount')
ax.set_title('Frequency of Donation Amounts for Treatment Group')
plt.show()
```

## Simulation Experiment

As a reminder of how the t-statistic "works," in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.

Suppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made. 

Further suppose that the true distribution of respondents who do get a charitable donation match of any size  is Bernoulli with probability p=0.022 that a donation is made.

### Law of Large Numbers

<!--_to do:  Make a plot like those on slide 43 from our first class and explain the plot to the reader. To do this, you will simulate 100,00 draws from the control distribution and 10,000 draws from the treatment distribution. You'll then calculate a vector of 10,000 differences, and then you'll plot the cumulative average of that vector of differences. Comment on whether the cumulative average approaches the true difference in means._-->

```{python}
# use a bernoulli distribution to simulate 10,000 trials for control and treatment groups using their mean percentage donated as the probabilities respectively

import numpy as np
from scipy.stats import bernoulli

control = karlan[karlan['treatment'] == 0]['gave'].mean()
treatment = karlan[karlan['treatment'] == 1]['gave'].mean()

control_sim = bernoulli.rvs(p = control, size = 10000)
treatment_sim = bernoulli.rvs(p = treatment, size = 10000)

# calculate cumulative average of the differences for the first 10,000 draws

cum_avg = np.cumsum(treatment_sim - control_sim) / np.arange(1, 10001)

cum_avg
```

```{python}
# plot the cumulative average of the differences with a line plot

fig, ax = plt.subplots()
ax.plot(cum_avg)
ax.axhline(treatment - control, color='red')
ax.set_ylabel('Cumulative Average of Differences')
ax.set_xlabel('Number of Draws')
ax.set_title('Cumulative Average of Differences in Proportion of Giving Money')
plt.show()
```

The above graph shows a simulation of the differences between simulated probabilities of an individual actually donating in the treatment group and an individual donating in the control group. The control group was given a probability of 0.018 and treatment group was given a probability of 0.022, which were both calculating from the given dataset.

We simulated this for the control and treatment group 10,000 times to generate the graph. The red horizontal line on the graph shows the calculated difference between the treatment and control probabilities from the dataset (0.004).

As shown, the cumulative difference between the treatment and control group varies greatly initially, then slowly starts to vary less and less around the average difference of 0.004. With more trials, it is expected there would be even less variability and the cumulative difference would be extremely close to 0.004. 

### Central Limit Theorem

<!--_to do: Make 4 histograms like those on slide 44 from our first class at sample sizes 50, 200, 500, and 1000 and explain these plots to the reader. To do this for a sample size of e.g. 50, take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that you have 1000 averages. Plot the histogram of those averages. Comment on whether zero is in the "middle" of the distribution or whether it's in the "tail."_-->

#### Simulating 50 trials

```{python}
n_50_c = np.random.binomial(50, 0.018, 1000)

n_50_c = n_50_c / 50

n_50_t = np.random.binomial(50, 0.022, 1000)

n_50_t = n_50_t / 50

n_50 = n_50_t - n_50_c

# make a histogram of n_50 so there is no spacing between the bars

fig, ax = plt.subplots()
ax.hist(n_50, bins=10, rwidth=1)
ax.axvline(n_50.mean(), color='red')
ax.text(n_50.mean(), ax.get_ylim()[1]*0.9, f'{np.round(n_50.mean(),4)}', color='red', verticalalignment='center', horizontalalignment='center')
ax.set_ylabel('Frequency')
ax.set_xlabel('Difference in Proportion of Donors (Treatment - Control) in 50 Draws')
ax.set_title('Frequency of Proportion of Control Group that Gave Money in 50 Draws')
plt.show()
```

#### Simulating 200 trials

```{python}
n_200_c = np.random.binomial(200, 0.018, 1000)/200

n_200_t = np.random.binomial(200, 0.022, 1000)/200


n_200 = n_200_t - n_200_c

n_200_mean = n_200.mean()

fig, ax = plt.subplots()
ax.hist(n_200, bins=10, rwidth=1)
ax.axvline(n_200_mean, color='red')
ax.text(n_200_mean, ax.get_ylim()[1]*0.9, f'{np.round(n_200_mean,4)}', color='red', verticalalignment='center', horizontalalignment='center')
ax.set_ylabel('Frequency')
ax.set_xlabel('Difference in Proportion of Donors (Treatment - Control) in 200 Draws')
ax.set_title('Frequency of Proportion of Control Group that Gave Money in 200 Draws')
plt.show()
```

#### Simulating 500 trials

```{python}
n_500_c = np.random.binomial(500, 0.018, 1000)/500

n_500_t = np.random.binomial(500, 0.022, 1000)/500


n_500 = n_500_t - n_500_c

n_500_mean = n_500.mean()

fig, ax = plt.subplots()
ax.hist(n_500, bins=10, rwidth=1)
ax.axvline(n_500_mean, color='red')
ax.text(n_500_mean, ax.get_ylim()[1]*0.9, f'{np.round(n_500_mean,4)}', color='red', verticalalignment='center', horizontalalignment='center')
ax.set_ylabel('Frequency')
ax.set_xlabel('Difference in Proportion of Donors (Treatment - Control) in 500 Draws')
ax.set_title('Frequency of Proportion of Control Group that Gave Money in 500 Draws')
plt.show()
```

#### Simulating 1000 trials

```{python}

n_1000_c = np.random.binomial(1000, 0.018, 1000)/1000

n_1000_t = np.random.binomial(1000, 0.022, 1000)/1000

n_1000 = n_1000_t - n_1000_c

n_1000_mean = n_1000.mean()

fig, ax = plt.subplots()
ax.hist(n_1000, bins=10, rwidth=1)
ax.axvline(n_1000_mean, color='red')
ax.text(n_1000_mean, ax.get_ylim()[1]*0.9, f'{np.round(n_1000_mean,4)}', color='red', verticalalignment='center', horizontalalignment='right')
ax.set_ylabel('Frequency')
ax.set_xlabel('Difference in Proportion of Donors (Treatment - Control) in 500 Draws')
ax.set_title('Frequency of Proportion of Control Group that Gave Money in 500 Draws')
plt.show()
```

From the above histograms, you can see from the red vertical line that the average difference decreases as we increase the trial size of the simulation and starts to get closer to 0.004, which is the calculated difference from the dataset between the percentage that donated from the treatment group versus the control group.

Although the 0 mark on the x-axis varies because of graph sizing, you can see that the outer limits of the distribution gets smaller as we increase the number of trials. This follows the central limit theorem, since as we increase the number of trials in each simulation, we will get closer and closer to the true mean or percentage. The variation or wide distribution we see in the 50 trial simulation is no longer there in the 1000 trial distribution.

Overall, the more trials we have in our simulation or experiment, the closer we will get to the mean. 